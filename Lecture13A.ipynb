{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings in Keras**\n",
        "* ## Instead of using one hot encoding for each unique word, more meaningful word embeddings can be used\n",
        "* ## E.g., Word2Vec, GloVe (Global Vectors for Word Representation)\n",
        "> * ### You will study them in details in dedicated classes\n",
        "* ## Here we focus on how to learn a word embedding directly in Keras usinf the ```Embedding``` layer\n",
        "> * ### It learns a linear transformation matrix ***E*** that maps the one hot vectors representing the $n$ distinct words onto lower-dimensional feature vectors, the embedding space of dimension $d$\n",
        "> * ### Then, **to save computation, it stores the lookup table of size $n\\times d$ containing the embedding for each unique word** (index from $0$ to $n-1$)\n",
        ">> ### unfortunately, this means the parameters are not the weight in $E$, but directly the embeding values!\n",
        ">> * #### so $n\\times d$ parameters!\n",
        "> * ### **Example**. With $10$ words and embedding dimension $2$, the lookup table can similar to"
      ],
      "metadata": {
        "id": "XfbhxkCzhLbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# +------------+------------+\n",
        "# |   index    |  Embedding |\n",
        "# +------------+------------+\n",
        "# |     0      | [1.2, 3.1] |\n",
        "# |     1      | [0.1, 4.2] |\n",
        "# |     2      | [1.0, 3.1] |\n",
        "# |     3      | [0.3, 2.1] |\n",
        "# |     4      | [2.2, 1.4] |\n",
        "# |     5      | [0.7, 1.7] |\n",
        "# |     6      | [4.1, 2.0] |\n",
        "# |     7      | [0.1, 1.4] |\n",
        "# |     8      | [0.2, 1.3] |\n",
        "# |     9      | [4.3, 2.7] |\n",
        "# +------------+------------+"
      ],
      "metadata": {
        "id": "47GgwDf9RvA1"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">  ### Thus, the word of index $2$, which would correspond to the one-hot vector $v_2 = (0,0,1,0,0,0,0,0,0,0,0)$, is embedded onto the vector $v_2\\cdot\\boldsymbol{E}=(1.0,3.1)$.\n",
        "> ### **The transofmation matrix $\\boldsymbol{E}$, however, is only symbolic, it is not computed nor stored**\n",
        "> ### **Since we learn directly the results of the dot product input one hot vector dot product $E$,  we do not neither need to perform the dot product**\n",
        "> * ### The main difference with standard word embedding strategies is that embedding trained as any other parameter in the model via backpropagation\n",
        "> * ### Accordingly, it is not able to capture general word semantic similarities, but only some word features specific for the current task  "
      ],
      "metadata": {
        "id": "myNHmM0UR7Ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Keras Embedding Layer** ([docs](https://keras.io/api/layers/core_layers/embedding/))"
      ],
      "metadata": {
        "id": "OaFGDiMaUfSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![emb_layer.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "9OBOk4hBVuuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Arguments\n",
        "* ### **input_dim**: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "* ### **output_dim**: Integer. Dimension of the dense embedding.\n",
        "* ### **input_length**: Integer. Length of sequence of words received as input (temporal steps of the subsequent LSTM)"
      ],
      "metadata": {
        "id": "vU11wOAnVu2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accordingly, **we do not need to transforms words into their one-hot vectors**, we can supply just their intergers and use the *sparse_categorical_crossentropy* loss\n",
        "# Let's repeat the experiment with Gutemberg ebook"
      ],
      "metadata": {
        "id": "Jne1b7F1WjBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Embedding\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "5AfHHoBOWElf"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://www.gutenberg.org/files/1661/1661-0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kk6r1Soy3Qu",
        "outputId": "a6ce7964-5348-49d5-b49c-c3ed825ba6cc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  593k  100  593k    0     0   319k      0  0:00:01  0:00:01 --:--:--  319k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLf_RvAH-LYR",
        "outputId": "3c2e67d2-6c7c-42bc-8611-bab8b1cdd680"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1661-0.txt  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvReA84K4Tj2",
        "outputId": "12a746a4-14cf-40f5-86bc-e1c70f47d666"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '1661-0.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length, number of characters:', len(text))\n",
        "print(f\"text[:100]:{text[:100]}\")\n",
        "max_size=100000\n",
        "# cutting text due to memory size limitations\n",
        "text = text[:max_size]\n",
        "print('selected length, number of characters:', len(text))"
      ],
      "metadata": {
        "id": "KmKWkLlJcPOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa886d41-6db8-4846-d74b-675159956dde"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length, number of characters: 581425\n",
            "text[:100]:the project gutenberg ebook of the adventures of sherlock holmes,\n",
            "by arthur conan doyle\n",
            "\n",
            "this ebook\n",
            "selected length, number of characters: 100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def get_words(text):\n",
        "  text = text.replace('--', ' ')\n",
        "  # split into tokens by white space\n",
        "  words = text.split()\n",
        "  # remove punctuation from each token\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  words = [w.translate(table) for w in words]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in words if word.isalpha()]\n",
        "  # make lower case\n",
        "  words = [word.lower() for word in words]\n",
        "  return words\n",
        "\n",
        "words = get_words(text)\n",
        "tot_uniq_words =  len(set(words))\n",
        "print(words[:20])\n",
        "print(f\"Total words: {len(words)}\")\n",
        "print(f\"Unique words: {tot_uniq_words}\")"
      ],
      "metadata": {
        "id": "z-u5D_wUcLKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e472b842-97f3-451d-a184-5b7b4b13fb45"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of']\n",
            "Total words: 17106\n",
            "Unique words: 3019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a dictionary of unique strings, associated with a unique integer, starting from ```0``` to ```len(unique_words) - 1```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zzgsUXAOpMwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
        "print(f\"unique_word_index:{unique_word_index}\")\n",
        "print(f\"Unique words[:10]:{unique_words[:10]}\")"
      ],
      "metadata": {
        "id": "F-3qNmN4pg95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f9ba62-7986-446a-b878-6588535e5888"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_word_index:{np.str_('a'): 0, np.str_('abandoned'): 1, np.str_('abbots'): 2, np.str_('abhorrent'): 3, np.str_('able'): 4, np.str_('about'): 5, np.str_('above'): 6, np.str_('abruptly'): 7, np.str_('absence'): 8, np.str_('absolute'): 9, np.str_('absolutely'): 10, np.str_('absorb'): 11, np.str_('abutted'): 12, np.str_('accent'): 13, np.str_('accomplice'): 14, np.str_('accomplished'): 15, np.str_('account'): 16, np.str_('accountant'): 17, np.str_('accustomed'): 18, np.str_('acid'): 19, np.str_('acknowledge'): 20, np.str_('acknowledges'): 21, np.str_('acquaintance'): 22, np.str_('across'): 23, np.str_('action'): 24, np.str_('actions'): 25, np.str_('active'): 26, np.str_('activity'): 27, np.str_('actor'): 28, np.str_('actress'): 29, np.str_('acute'): 30, np.str_('added'): 31, np.str_('addition'): 32, np.str_('address'): 33, np.str_('addressing'): 34, np.str_('adjusted'): 35, np.str_('adler'): 36, np.str_('admirable'): 37, np.str_('admirably'): 38, np.str_('admiration'): 39, np.str_('admit'): 40, np.str_('adopted'): 41, np.str_('advantage'): 42, np.str_('advantages'): 43, np.str_('adventure'): 44, np.str_('adventures'): 45, np.str_('adventuress'): 46, np.str_('advertisement'): 47, np.str_('advice'): 48, np.str_('advise'): 49, np.str_('adviser'): 50, np.str_('affair'): 51, np.str_('affect'): 52, np.str_('afraid'): 53, np.str_('after'): 54, np.str_('afternoon'): 55, np.str_('afterwards'): 56, np.str_('again'): 57, np.str_('against'): 58, np.str_('age'): 59, np.str_('agent'): 60, np.str_('agitation'): 61, np.str_('ago'): 62, np.str_('agra'): 63, np.str_('agree'): 64, np.str_('ah'): 65, np.str_('air'): 66, np.str_('aisle'): 67, np.str_('akin'): 68, np.str_('alarm'): 69, np.str_('albert'): 70, np.str_('aldersgate'): 71, np.str_('all'): 72, np.str_('allimportant'): 73, np.str_('allow'): 74, np.str_('almost'): 75, np.str_('alone'): 76, np.str_('along'): 77, np.str_('already'): 78, np.str_('also'): 79, np.str_('altar'): 80, np.str_('alternately'): 81, np.str_('alternating'): 82, np.str_('altogether'): 83, np.str_('always'): 84, np.str_('am'): 85, np.str_('amazement'): 86, np.str_('amazing'): 87, np.str_('ambition'): 88, np.str_('american'): 89, np.str_('amiable'): 90, np.str_('amid'): 91, np.str_('amiss'): 92, np.str_('among'): 93, np.str_('amount'): 94, np.str_('amply'): 95, np.str_('an'): 96, np.str_('and'): 97, np.str_('animated'): 98, np.str_('announced'): 99, np.str_('announcement'): 100, np.str_('annoyance'): 101, np.str_('anonymous'): 102, np.str_('another'): 103, np.str_('answer'): 104, np.str_('answered'): 105, np.str_('antagonist'): 106, np.str_('anxious'): 107, np.str_('any'): 108, np.str_('anyhow'): 109, np.str_('anyone'): 110, np.str_('anything'): 111, np.str_('anywhere'): 112, np.str_('apart'): 113, np.str_('aperture'): 114, np.str_('apiece'): 115, np.str_('apology'): 116, np.str_('apparent'): 117, np.str_('apparently'): 118, np.str_('appearance'): 119, np.str_('appeared'): 120, np.str_('appears'): 121, np.str_('apply'): 122, np.str_('applying'): 123, np.str_('april'): 124, np.str_('aquiline'): 125, np.str_('arcandcompass'): 126, np.str_('archery'): 127, np.str_('archie'): 128, np.str_('architecture'): 129, np.str_('are'): 130, np.str_('area'): 131, np.str_('arm'): 132, np.str_('armchair'): 133, np.str_('armed'): 134, np.str_('armour'): 135, np.str_('arms'): 136, np.str_('army'): 137, np.str_('arnsworth'): 138, np.str_('around'): 139, np.str_('arranged'): 140, np.str_('arrived'): 141, np.str_('arteries'): 142, np.str_('arthur'): 143, np.str_('artificial'): 144, np.str_('as'): 145, np.str_('ascertaining'): 146, np.str_('ashamed'): 147, np.str_('aside'): 148, np.str_('ask'): 149, np.str_('askance'): 150, np.str_('asked'): 151, np.str_('asks'): 152, np.str_('asleep'): 153, np.str_('asserted'): 154, np.str_('assistant'): 155, np.str_('assistants'): 156, np.str_('assisting'): 157, np.str_('associated'): 158, np.str_('assumed'): 159, np.str_('assure'): 160, np.str_('assuring'): 161, np.str_('astrakhan'): 162, np.str_('astuteness'): 163, np.str_('at'): 164, np.str_('atkinson'): 165, np.str_('atmosphere'): 166, np.str_('attempt'): 167, np.str_('attempts'): 168, np.str_('attend'): 169, np.str_('attended'): 170, np.str_('attention'): 171, np.str_('attica'): 172, np.str_('attitude'): 173, np.str_('attracted'): 174, np.str_('august'): 175, np.str_('author'): 176, np.str_('authoritative'): 177, np.str_('autumn'): 178, np.str_('avenue'): 179, np.str_('average'): 180, np.str_('averse'): 181, np.str_('awaiting'): 182, np.str_('aware'): 183, np.str_('away'): 184, np.str_('awkward'): 185, np.str_('baby'): 186, np.str_('bachelor'): 187, np.str_('back'): 188, np.str_('backward'): 189, np.str_('bad'): 190, np.str_('bade'): 191, np.str_('baffled'): 192, np.str_('bag'): 193, np.str_('baggy'): 194, np.str_('bags'): 195, np.str_('baker'): 196, np.str_('balanced'): 197, np.str_('balancing'): 198, np.str_('bald'): 199, np.str_('balls'): 200, np.str_('band'): 201, np.str_('bands'): 202, np.str_('bank'): 203, np.str_('banker'): 204, np.str_('banks'): 205, np.str_('barbaric'): 206, np.str_('barrel'): 207, np.str_('barrow'): 208, np.str_('bashful'): 209, np.str_('be'): 210, np.str_('beamed'): 211, np.str_('bear'): 212, np.str_('beat'): 213, np.str_('beaten'): 214, np.str_('beating'): 215, np.str_('beauties'): 216, np.str_('beautiful'): 217, np.str_('beautifully'): 218, np.str_('became'): 219, np.str_('because'): 220, np.str_('become'): 221, np.str_('becomes'): 222, np.str_('bed'): 223, np.str_('bedroom'): 224, np.str_('bedtime'): 225, np.str_('beeches'): 226, np.str_('beef'): 227, np.str_('been'): 228, np.str_('before'): 229, np.str_('beg'): 230, np.str_('began'): 231, np.str_('begin'): 232, np.str_('begins'): 233, np.str_('behind'): 234, np.str_('being'): 235, np.str_('belief'): 236, np.str_('believe'): 237, np.str_('bell'): 238, np.str_('bellpull'): 239, np.str_('below'): 240, np.str_('benefactor'): 241, np.str_('benevolent'): 242, np.str_('bequest'): 243, np.str_('berths'): 244, np.str_('beryl'): 245, np.str_('beside'): 246, np.str_('besides'): 247, np.str_('best'): 248, np.str_('betrayed'): 249, np.str_('betrothal'): 250, np.str_('better'): 251, np.str_('between'): 252, np.str_('beyond'): 253, np.str_('bijou'): 254, np.str_('bill'): 255, np.str_('billet'): 256, np.str_('binding'): 257, np.str_('biographies'): 258, np.str_('biography'): 259, np.str_('bird'): 260, np.str_('bit'): 261, np.str_('bizarre'): 262, np.str_('black'): 263, np.str_('blackest'): 264, np.str_('blackletter'): 265, np.str_('blackmailing'): 266, np.str_('blandly'): 267, np.str_('blazing'): 268, np.str_('blind'): 269, np.str_('blinds'): 270, np.str_('block'): 271, np.str_('blocked'): 272, np.str_('blood'): 273, np.str_('blottingpaper'): 274, np.str_('blow'): 275, np.str_('blue'): 276, np.str_('board'): 277, np.str_('bob'): 278, np.str_('body'): 279, np.str_('bohemia'): 280, np.str_('bohemian'): 281, np.str_('bonnet'): 282, np.str_('books'): 283, np.str_('boots'): 284, np.str_('bootslitting'): 285, np.str_('bore'): 286, np.str_('born'): 287, np.str_('borne'): 288, np.str_('borrowed'): 289, np.str_('boscombe'): 290, np.str_('boswell'): 291, np.str_('both'): 292, np.str_('bottle'): 293, np.str_('bought'): 294, np.str_('bound'): 295, np.str_('bow'): 296, np.str_('bowed'): 297, np.str_('boxes'): 298, np.str_('boy'): 299, np.str_('boyish'): 300, np.str_('bracelets'): 301, np.str_('brain'): 302, np.str_('branch'): 303, np.str_('brassy'): 304, np.str_('brave'): 305, np.str_('breaking'): 306, np.str_('breaks'): 307, np.str_('breathing'): 308, np.str_('brick'): 309, np.str_('bride'): 310, np.str_('bridegroom'): 311, np.str_('briefly'): 312, np.str_('bright'): 313, np.str_('brightlooking'): 314, np.str_('brightly'): 315, np.str_('brilliant'): 316, np.str_('brilliantly'): 317, np.str_('bring'): 318, np.str_('briony'): 319, np.str_('britannica'): 320, np.str_('british'): 321, np.str_('broad'): 322, np.str_('broadbrimmed'): 323, np.str_('broke'): 324, np.str_('broken'): 325, np.str_('brooch'): 326, np.str_('brothers'): 327, np.str_('brougham'): 328, np.str_('brought'): 329, np.str_('brown'): 330, np.str_('bruise'): 331, np.str_('brushed'): 332, np.str_('buckles'): 333, np.str_('budge'): 334, np.str_('build'): 335, np.str_('building'): 336, np.str_('built'): 337, np.str_('bulge'): 338, np.str_('bulky'): 339, np.str_('bulldog'): 340, np.str_('bullion'): 341, np.str_('burglars'): 342, np.str_('buried'): 343, np.str_('burned'): 344, np.str_('burrowing'): 345, np.str_('burst'): 346, np.str_('bushes'): 347, np.str_('busier'): 348, np.str_('business'): 349, np.str_('busy'): 350, np.str_('but'): 351, np.str_('butted'): 352, np.str_('buttoning'): 353, np.str_('by'): 354, np.str_('cab'): 355, np.str_('cabby'): 356, np.str_('cabinet'): 357, np.str_('cabman'): 358, np.str_('cabs'): 359, np.str_('call'): 360, np.str_('called'): 361, np.str_('calls'): 362, np.str_('calves'): 363, np.str_('came'): 364, np.str_('camera'): 365, np.str_('campaign'): 366, np.str_('can'): 367, np.str_('candid'): 368, np.str_('candidate'): 369, np.str_('cannot'): 370, np.str_('cap'): 371, np.str_('capable'): 372, np.str_('capital'): 373, np.str_('carbuncle'): 374, np.str_('card'): 375, np.str_('cardboard'): 376, np.str_('cards'): 377, np.str_('care'): 378, np.str_('cared'): 379, np.str_('careful'): 380, np.str_('carefully'): 381, np.str_('careless'): 382, np.str_('carelessly'): 383, np.str_('carlsbad'): 384, np.str_('carriage'): 385, np.str_('carriagebuilding'): 386, np.str_('carried'): 387, np.str_('carries'): 388, np.str_('carry'): 389, np.str_('carre'): 390, np.str_('carte'): 391, np.str_('case'): 392, np.str_('cases'): 393, np.str_('casselfelstein'): 394, np.str_('castle'): 395, np.str_('catch'): 396, np.str_('caught'): 397, np.str_('cause'): 398, np.str_('caused'): 399, np.str_('ceased'): 400, np.str_('celebrated'): 401, np.str_('cellar'): 402, np.str_('centre'): 403, np.str_('centuries'): 404, np.str_('certain'): 405, np.str_('certainly'): 406, np.str_('chagrin'): 407, np.str_('chain'): 408, np.str_('chains'): 409, np.str_('chair'): 410, np.str_('chairman'): 411, np.str_('chairs'): 412, np.str_('chamber'): 413, np.str_('chambers'): 414, np.str_('chamois'): 415, np.str_('chance'): 416, np.str_('chances'): 417, np.str_('change'): 418, np.str_('changed'): 419, np.str_('character'): 420, np.str_('charing'): 421, np.str_('chase'): 422, np.str_('chat'): 423, np.str_('check'): 424, np.str_('cheekbones'): 425, np.str_('cheer'): 426, np.str_('chest'): 427, np.str_('child'): 428, np.str_('chin'): 429, np.str_('china'): 430, np.str_('chinese'): 431, np.str_('chink'): 432, np.str_('chisel'): 433, np.str_('choked'): 434, np.str_('choose'): 435, np.str_('chronicle'): 436, np.str_('chubb'): 437, np.str_('chuckled'): 438, np.str_('church'): 439, np.str_('cigarette'): 440, np.str_('cigars'): 441, np.str_('cigarshaped'): 442, np.str_('circumstances'): 443, np.str_('city'): 444, np.str_('civil'): 445, np.str_('claim'): 446, np.str_('clapped'): 447, np.str_('clasped'): 448, np.str_('clattered'): 449, np.str_('claws'): 450, np.str_('clay'): 451, np.str_('cleancut'): 452, np.str_('cleanshaven'): 453, np.str_('clear'): 454, np.str_('clearing'): 455, np.str_('clearly'): 456, np.str_('clergyman'): 457, np.str_('clever'): 458, np.str_('cleverness'): 459, np.str_('client'): 460, np.str_('clients'): 461, np.str_('climbing'): 462, np.str_('clinked'): 463, np.str_('cloak'): 464, np.str_('close'): 465, np.str_('closed'): 466, np.str_('closely'): 467, np.str_('closing'): 468, np.str_('cloth'): 469, np.str_('clothes'): 470, np.str_('clotilde'): 471, np.str_('cloud'): 472, np.str_('clouds'): 473, np.str_('clue'): 474, np.str_('clues'): 475, np.str_('clumps'): 476, np.str_('clumsy'): 477, np.str_('clutched'): 478, np.str_('coachhouse'): 479, np.str_('coachman'): 480, np.str_('coat'): 481, np.str_('coburg'): 482, np.str_('cocaine'): 483, np.str_('cocked'): 484, np.str_('coffee'): 485, np.str_('coin'): 486, np.str_('coincidences'): 487, np.str_('cold'): 488, np.str_('coldly'): 489, np.str_('collar'): 490, np.str_('colleague'): 491, np.str_('colour'): 492, np.str_('column'): 493, np.str_('combinations'): 494, np.str_('come'): 495, np.str_('comes'): 496, np.str_('comfortable'): 497, np.str_('comical'): 498, np.str_('coming'): 499, np.str_('commerce'): 500, np.str_('committed'): 501, np.str_('common'): 502, np.str_('commonplace'): 503, np.str_('commonplaces'): 504, np.str_('communicate'): 505, np.str_('communicative'): 506, np.str_('companion'): 507, np.str_('companions'): 508, np.str_('company'): 509, np.str_('comparing'): 510, np.str_('compelled'): 511, np.str_('competition'): 512, np.str_('complain'): 513, np.str_('complained'): 514, np.str_('complete'): 515, np.str_('completed'): 516, np.str_('completely'): 517, np.str_('complicates'): 518, np.str_('compliment'): 519, np.str_('complimented'): 520, np.str_('comply'): 521, np.str_('composer'): 522, np.str_('compromise'): 523, np.str_('compromised'): 524, np.str_('compromising'): 525, np.str_('compunction'): 526, np.str_('conan'): 527, np.str_('conceal'): 528, np.str_('concealment'): 529, np.str_('conceive'): 530, np.str_('concerning'): 531, np.str_('concert'): 532, np.str_('concerts'): 533, np.str_('conclusion'): 534, np.str_('conclusions'): 535, np.str_('condescend'): 536, np.str_('conditions'): 537, np.str_('conduct'): 538, np.str_('conducted'): 539, np.str_('confess'): 540, np.str_('confessed'): 541, np.str_('confidant'): 542, np.str_('confide'): 543, np.str_('confidence'): 544, np.str_('confined'): 545, np.str_('confused'): 546, np.str_('congratulate'): 547, np.str_('congratulated'): 548, np.str_('connected'): 549, np.str_('connection'): 550, np.str_('consequential'): 551, np.str_('considerable'): 552, np.str_('consideration'): 553, np.str_('consisted'): 554, np.str_('conspiring'): 555, np.str_('construction'): 556, np.str_('consult'): 557, np.str_('consulting'): 558, np.str_('contact'): 559, np.str_('contain'): 560, np.str_('contains'): 561, np.str_('contemplation'): 562, np.str_('contemplative'): 563, np.str_('contents'): 564, np.str_('continental'): 565, np.str_('continents'): 566, np.str_('continue'): 567, np.str_('continued'): 568, np.str_('contraction'): 569, np.str_('contrary'): 570, np.str_('contrast'): 571, np.str_('contributed'): 572, np.str_('convenience'): 573, np.str_('conventionalities'): 574, np.str_('conventions'): 575, np.str_('conversation'): 576, np.str_('conveyed'): 577, np.str_('convinced'): 578, np.str_('cooking'): 579, np.str_('coolest'): 580, np.str_('coolness'): 581, np.str_('copier'): 582, np.str_('copper'): 583, np.str_('copy'): 584, np.str_('copying'): 585, np.str_('cordially'): 586, np.str_('corner'): 587, np.str_('cornwall'): 588, np.str_('coronet'): 589, np.str_('correct'): 590, np.str_('corridor'): 591, np.str_('cost'): 592, np.str_('costume'): 593, np.str_('couch'): 594, np.str_('could'): 595, np.str_('count'): 596, np.str_('country'): 597, np.str_('counts'): 598, np.str_('couple'): 599, np.str_('couples'): 600, np.str_('course'): 601, np.str_('court'): 602, np.str_('crack'): 603, np.str_('cracks'): 604, np.str_('crate'): 605, np.str_('crates'): 606, np.str_('creature'): 607, np.str_('crib'): 608, np.str_('cried'): 609, np.str_('crime'): 610, np.str_('crimes'): 611, np.str_('criminal'): 612, np.str_('criminals'): 613, np.str_('crop'): 614, np.str_('cross'): 615, np.str_('crosspurposes'): 616, np.str_('crouched'): 617, np.str_('crowd'): 618, np.str_('crowded'): 619, np.str_('crown'): 620, np.str_('crudest'): 621, np.str_('cruelly'): 622, np.str_('cruelty'): 623, np.str_('crusted'): 624, np.str_('cry'): 625, np.str_('cuff'): 626, np.str_('cunning'): 627, np.str_('cup'): 628, np.str_('curb'): 629, np.str_('curiosity'): 630, np.str_('curious'): 631, np.str_('curled'): 632, np.str_('curt'): 633, np.str_('curve'): 634, np.str_('custody'): 635, np.str_('custom'): 636, np.str_('customary'): 637, np.str_('cuts'): 638, np.str_('daily'): 639, np.str_('daintiest'): 640, np.str_('danger'): 641, np.str_('dangling'): 642, np.str_('dank'): 643, np.str_('dare'): 644, np.str_('dared'): 645, np.str_('daring'): 646, np.str_('dark'): 647, np.str_('darkness'): 648, np.str_('darlington'): 649, np.str_('dashed'): 650, np.str_('dashing'): 651, np.str_('data'): 652, np.str_('date'): 653, np.str_('dated'): 654, np.str_('daughter'): 655, np.str_('dawn'): 656, np.str_('day'): 657, np.str_('days'): 658, np.str_('deal'): 659, np.str_('dealings'): 660, np.str_('dear'): 661, np.str_('death'): 662, np.str_('debts'): 663, np.str_('deceived'): 664, np.str_('deduce'): 665, np.str_('deduction'): 666, np.str_('deep'): 667, np.str_('deeper'): 668, np.str_('deepest'): 669, np.str_('deeply'): 670, np.str_('deepsea'): 671, np.str_('defeated'): 672, np.str_('deference'): 673, np.str_('degrees'): 674, np.str_('dejected'): 675, np.str_('delicacy'): 676, np.str_('delicate'): 677, np.str_('delicately'): 678, np.str_('delight'): 679, np.str_('dense'): 680, np.str_('departed'): 681, np.str_('departure'): 682, np.str_('depend'): 683, np.str_('depended'): 684, np.str_('depicted'): 685, np.str_('depot'): 686, np.str_('depressing'): 687, np.str_('descended'): 688, np.str_('description'): 689, np.str_('desire'): 690, np.str_('desires'): 691, np.str_('desirous'): 692, np.str_('despair'): 693, np.str_('desperation'): 694, np.str_('detail'): 695, np.str_('details'): 696, np.str_('detected'): 697, np.str_('detective'): 698, np.str_('determined'): 699, np.str_('deuce'): 700, np.str_('develop'): 701, np.str_('devouring'): 702, np.str_('did'): 703, np.str_('die'): 704, np.str_('died'): 705, np.str_('different'): 706, np.str_('difficult'): 707, np.str_('difficulties'): 708, np.str_('diligence'): 709, np.str_('dimly'): 710, np.str_('dingy'): 711, np.str_('dinner'): 712, np.str_('direction'): 713, np.str_('directions'): 714, np.str_('director'): 715, np.str_('directors'): 716, np.str_('dirty'): 717, np.str_('disadvantage'): 718, np.str_('disappearance'): 719, np.str_('disappeared'): 720, np.str_('disappointment'): 721, np.str_('discontent'): 722, np.str_('discover'): 723, np.str_('discovered'): 724, np.str_('discretion'): 725, np.str_('discuss'): 726, np.str_('disentangled'): 727, np.str_('disguises'): 728, np.str_('disgust'): 729, np.str_('dismantled'): 730, np.str_('dismissed'): 731, np.str_('disqualify'): 732, np.str_('disreputable'): 733, np.str_('dissolved'): 734, np.str_('distinction'): 735, np.str_('distinguish'): 736, np.str_('distracting'): 737, np.str_('disturbing'): 738, np.str_('dived'): 739, np.str_('diverted'): 740, np.str_('diving'): 741, np.str_('do'): 742, np.str_('docketing'): 743, np.str_('doctor'): 744, np.str_('does'): 745, np.str_('dog'): 746, np.str_('doing'): 747, np.str_('doings'): 748, np.str_('done'): 749, np.str_('donna'): 750, np.str_('door'): 751, np.str_('doormat'): 752, np.str_('double'): 753, np.str_('doublebreasted'): 754, np.str_('doubleedged'): 755, np.str_('doubt'): 756, np.str_('down'): 757, np.str_('doyle'): 758, np.str_('dozen'): 759, np.str_('dr'): 760, np.str_('drab'): 761, np.str_('draw'): 762, np.str_('drawers'): 763, np.str_('drawing'): 764, np.str_('drawingroom'): 765, np.str_('drawn'): 766, np.str_('dreadful'): 767, np.str_('dreams'): 768, np.str_('dreamy'): 769, np.str_('dress'): 770, np.str_('dressed'): 771, np.str_('drew'): 772, np.str_('drifted'): 773, np.str_('drink'): 774, np.str_('drive'): 775, np.str_('driven'): 776, np.str_('driver'): 777, np.str_('drives'): 778, np.str_('driving'): 779, np.str_('drop'): 780, np.str_('dropped'): 781, np.str_('drove'): 782, np.str_('drowsiness'): 783, np.str_('drug'): 784, np.str_('drugcreated'): 785, np.str_('drunkenlooking'): 786, np.str_('dryly'): 787, np.str_('dual'): 788, np.str_('dubious'): 789, np.str_('duke'): 790, np.str_('dull'): 791, np.str_('duncan'): 792, np.str_('dundas'): 793, np.str_('during'): 794, np.str_('dusk'): 795, np.str_('each'): 796, np.str_('eagerly'): 797, np.str_('ear'): 798, np.str_('early'): 799, np.str_('earn'): 800, np.str_('earnestly'): 801, np.str_('earning'): 802, np.str_('ears'): 803, np.str_('earth'): 804, np.str_('earthsmelling'): 805, np.str_('ease'): 806, np.str_('easily'): 807, np.str_('east'): 808, np.str_('easy'): 809, np.str_('eat'): 810, np.str_('ebook'): 811, np.str_('eclipses'): 812, np.str_('edge'): 813, np.str_('edges'): 814, np.str_('edgeware'): 815, np.str_('editions'): 816, np.str_('edward'): 817, np.str_('effect'): 818, np.str_('effects'): 819, np.str_('effort'): 820, np.str_('effusive'): 821, np.str_('egria'): 822, np.str_('eight'): 823, np.str_('either'): 824, np.str_('ejaculated'): 825, np.str_('elaborate'): 826, np.str_('elbow'): 827, np.str_('elbowed'): 828, np.str_('elderly'): 829, np.str_('eleven'): 830, np.str_('eligible'): 831, np.str_('else'): 832, np.str_('embellish'): 833, np.str_('emerald'): 834, np.str_('emerged'): 835, np.str_('emotion'): 836, np.str_('emotions'): 837, np.str_('employed'): 838, np.str_('employers'): 839, np.str_('employing'): 840, np.str_('employs'): 841, np.str_('employ'): 842, np.str_('empty'): 843, np.str_('enclosure'): 844, np.str_('encoding'): 845, np.str_('encyclopdia'): 846, np.str_('end'): 847, np.str_('endeavour'): 848, np.str_('endeavoured'): 849, np.str_('endeavouring'): 850, np.str_('ended'): 851, np.str_('endless'): 852, np.str_('energetic'): 853, np.str_('energy'): 854, np.str_('engaged'): 855, np.str_('england'): 856, np.str_('english'): 857, np.str_('enormous'): 858, np.str_('enough'): 859, np.str_('entangled'): 860, np.str_('enter'): 861, np.str_('entered'): 862, np.str_('entering'): 863, np.str_('entertaining'): 864, np.str_('enthusiasm'): 865, np.str_('enthusiastic'): 866, np.str_('entirely'): 867, np.str_('entitles'): 868, np.str_('enwrapped'): 869, np.str_('epistle'): 870, np.str_('equalled'): 871, np.str_('equally'): 872, np.str_('escape'): 873, np.str_('escaped'): 874, np.str_('especially'): 875, np.str_('esq'): 876, np.str_('essence'): 877, np.str_('essential'): 878, np.str_('establishment'): 879, np.str_('eton'): 880, np.str_('europe'): 881, np.str_('european'): 882, np.str_('even'): 883, np.str_('evening'): 884, np.str_('events'): 885, np.str_('ever'): 886, np.str_('every'): 887, np.str_('everybody'): 888, np.str_('everyday'): 889, np.str_('everyone'): 890, np.str_('everything'): 891, np.str_('evident'): 892, np.str_('evidently'): 893, np.str_('evil'): 894, np.str_('ex'): 895, np.str_('exact'): 896, np.str_('exactly'): 897, np.str_('exactness'): 898, np.str_('exaggerated'): 899, np.str_('exalted'): 900, np.str_('examine'): 901, np.str_('examined'): 902, np.str_('example'): 903, np.str_('exceedingly'): 904, np.str_('excellent'): 905, np.str_('except'): 906, np.str_('exchange'): 907, np.str_('excitedly'): 908, np.str_('excitement'): 909, np.str_('exciting'): 910, np.str_('exclaimed'): 911, np.str_('excuse'): 912, np.str_('excuses'): 913, np.str_('existence'): 914, np.str_('expect'): 915, np.str_('expectancy'): 916, np.str_('expected'): 917, np.str_('expedition'): 918, np.str_('expenditure'): 919, np.str_('expense'): 920, np.str_('expensive'): 921, np.str_('experience'): 922, np.str_('experienced'): 923, np.str_('experiences'): 924, np.str_('explain'): 925, np.str_('explained'): 926, np.str_('explaining'): 927, np.str_('explanation'): 928, np.str_('explore'): 929, np.str_('expostulating'): 930, np.str_('expression'): 931, np.str_('extended'): 932, np.str_('extending'): 933, np.str_('extra'): 934, np.str_('extraordinary'): 935, np.str_('extreme'): 936, np.str_('eye'): 937, np.str_('eyes'): 938, np.str_('ezekiah'): 939, np.str_('face'): 940, np.str_('faced'): 941, np.str_('fact'): 942, np.str_('factor'): 943, np.str_('facts'): 944, np.str_('faculties'): 945, np.str_('faded'): 946, np.str_('fail'): 947, np.str_('failing'): 948, np.str_('fairly'): 949, np.str_('fall'): 950, np.str_('false'): 951, np.str_('familiar'): 952, np.str_('families'): 953, np.str_('family'): 954, np.str_('fancy'): 955, np.str_('fantastic'): 956, np.str_('far'): 957, np.str_('fare'): 958, np.str_('farrington'): 959, np.str_('fascinating'): 960, np.str_('fashion'): 961, np.str_('fast'): 962, np.str_('fasteners'): 963, np.str_('faster'): 964, np.str_('fatal'): 965, np.str_('fatencircled'): 966, np.str_('fault'): 967, np.str_('faults'): 968, np.str_('favour'): 969, np.str_('favourable'): 970, np.str_('fear'): 971, np.str_('feared'): 972, np.str_('featureless'): 973, np.str_('features'): 974, np.str_('feel'): 975, np.str_('feet'): 976, np.str_('fell'): 977, np.str_('fellow'): 978, np.str_('felt'): 979, np.str_('few'): 980, np.str_('fiction'): 981, np.str_('field'): 982, np.str_('fierce'): 983, np.str_('fiery'): 984, np.str_('fifty'): 985, np.str_('fight'): 986, np.str_('figure'): 987, np.str_('figures'): 988, np.str_('fill'): 989, np.str_('filled'): 990, np.str_('fills'): 991, np.str_('filthy'): 992, np.str_('finally'): 993, np.str_('find'): 994, np.str_('finds'): 995, np.str_('fine'): 996, np.str_('finely'): 997, np.str_('finger'): 998, np.str_('fingers'): 999, np.str_('fingertips'): 1000, np.str_('finished'): 1001, np.str_('fire'): 1002, np.str_('firelight'): 1003, np.str_('first'): 1004, np.str_('fish'): 1005, np.str_('fishes'): 1006, np.str_('fists'): 1007, np.str_('fitted'): 1008, np.str_('five'): 1009, np.str_('fix'): 1010, np.str_('flags'): 1011, np.str_('flamecoloured'): 1012, np.str_('flaming'): 1013, np.str_('flash'): 1014, np.str_('flashed'): 1015, np.str_('flattened'): 1016, np.str_('flaubert'): 1017, np.str_('fleet'): 1018, np.str_('flight'): 1019, np.str_('flirting'): 1020, np.str_('floor'): 1021, np.str_('floridfaced'): 1022, np.str_('flowing'): 1023, np.str_('flurried'): 1024, np.str_('flushed'): 1025, np.str_('flushing'): 1026, np.str_('fly'): 1027, np.str_('foil'): 1028, np.str_('folk'): 1029, np.str_('follow'): 1030, np.str_('followed'): 1031, np.str_('following'): 1032, np.str_('follows'): 1033, np.str_('fondness'): 1034, np.str_('food'): 1035, np.str_('foolscap'): 1036, np.str_('foot'): 1037, np.str_('footpaths'): 1038, np.str_('for'): 1039, np.str_('forced'): 1040, np.str_('forefinger'): 1041, np.str_('forehead'): 1042, np.str_('foreseen'): 1043, np.str_('forever'): 1044, np.str_('forfeit'): 1045, np.str_('forger'): 1046, np.str_('forgot'): 1047, np.str_('form'): 1048, np.str_('former'): 1049, np.str_('formerly'): 1050, np.str_('formidable'): 1051, np.str_('fortunate'): 1052, np.str_('fortune'): 1053, np.str_('fortunes'): 1054, np.str_('forward'): 1055, np.str_('found'): 1056, np.str_('founded'): 1057, np.str_('four'): 1058, np.str_('fourteen'): 1059, np.str_('fourth'): 1060, np.str_('france'): 1061, np.str_('frankly'): 1062, np.str_('fraud'): 1063, np.str_('frayed'): 1064, np.str_('freedom'): 1065, np.str_('freely'): 1066, np.str_('freemason'): 1067, np.str_('freemasonry'): 1068, np.str_('french'): 1069, np.str_('frenchman'): 1070, np.str_('frequently'): 1071, np.str_('fresh'): 1072, np.str_('friday'): 1073, np.str_('friend'): 1074, np.str_('fro'): 1075, np.str_('frockcoat'): 1076, np.str_('from'): 1077, np.str_('front'): 1078, np.str_('fronts'): 1079, np.str_('full'): 1080, np.str_('fund'): 1081, np.str_('funny'): 1082, np.str_('fur'): 1083, np.str_('furnish'): 1084, np.str_('furnished'): 1085, np.str_('furniture'): 1086, np.str_('future'): 1087, np.str_('gain'): 1088, np.str_('gained'): 1089, np.str_('game'): 1090, np.str_('gang'): 1091, np.str_('gaping'): 1092, np.str_('garden'): 1093, np.str_('gash'): 1094, np.str_('gaslit'): 1095, np.str_('gasogene'): 1096, np.str_('gate'): 1097, np.str_('gave'): 1098, np.str_('gaze'): 1099, np.str_('gazed'): 1100, np.str_('general'): 1101, np.str_('generally'): 1102, np.str_('generations'): 1103, np.str_('gentle'): 1104, np.str_('gentleman'): 1105, np.str_('gentlemen'): 1106, np.str_('gently'): 1107, np.str_('george'): 1108, np.str_('german'): 1109, np.str_('germanspeaking'): 1110, np.str_('gesture'): 1111, np.str_('get'): 1112, np.str_('gets'): 1113, np.str_('getting'): 1114, np.str_('gibe'): 1115, np.str_('gigantic'): 1116, np.str_('gilt'): 1117, np.str_('gipsy'): 1118, np.str_('girl'): 1119, np.str_('give'): 1120, np.str_('given'): 1121, np.str_('gives'): 1122, np.str_('glad'): 1123, np.str_('glance'): 1124, np.str_('glanced'): 1125, np.str_('glances'): 1126, np.str_('glancing'): 1127, np.str_('glass'): 1128, np.str_('glassfactories'): 1129, np.str_('gleam'): 1130, np.str_('glimpse'): 1131, np.str_('glimpses'): 1132, np.str_('glint'): 1133, np.str_('gloom'): 1134, np.str_('gloomily'): 1135, np.str_('go'): 1136, np.str_('godfrey'): 1137, np.str_('goes'): 1138, np.str_('going'): 1139, np.str_('gold'): 1140, np.str_('golden'): 1141, np.str_('gone'): 1142, np.str_('good'): 1143, np.str_('goodbye'): 1144, np.str_('goodday'): 1145, np.str_('goodfortune'): 1146, np.str_('goodness'): 1147, np.str_('goodnight'): 1148, np.str_('goose'): 1149, np.str_('gospel'): 1150, np.str_('got'): 1151, np.str_('gottsreich'): 1152, np.str_('grabs'): 1153, np.str_('grace'): 1154, np.str_('grand'): 1155, np.str_('grandfather'): 1156, np.str_('grasp'): 1157, np.str_('grasping'): 1158, np.str_('grass'): 1159, np.str_('grating'): 1160, np.str_('gravely'): 1161, np.str_('graver'): 1162, np.str_('great'): 1163, np.str_('greatcoat'): 1164, np.str_('greatest'): 1165, np.str_('greeting'): 1166, np.str_('grey'): 1167, np.str_('grievance'): 1168, np.str_('grim'): 1169, np.str_('grit'): 1170, np.str_('groan'): 1171, np.str_('groom'): 1172, np.str_('gross'): 1173, np.str_('grotesque'): 1174, np.str_('ground'): 1175, np.str_('group'): 1176, np.str_('grow'): 1177, np.str_('grown'): 1178, np.str_('guardianship'): 1179, np.str_('guardsmen'): 1180, np.str_('guess'): 1181, np.str_('guessed'): 1182, np.str_('guidance'): 1183, np.str_('guide'): 1184, np.str_('guinea'): 1185, np.str_('guineas'): 1186, np.str_('gustave'): 1187, np.str_('gutenberg'): 1188, np.str_('ha'): 1189, np.str_('habit'): 1190, np.str_('habits'): 1191, np.str_('had'): 1192, np.str_('hair'): 1193, np.str_('half'): 1194, np.str_('halfandhalf'): 1195, np.str_('halfbuttoned'): 1196, np.str_('halfdragged'): 1197, np.str_('halfway'): 1198, np.str_('hall'): 1199, np.str_('hammered'): 1200, np.str_('hand'): 1201, np.str_('handcuffs'): 1202, np.str_('handed'): 1203, np.str_('hands'): 1204, np.str_('handsome'): 1205, np.str_('handy'): 1206, np.str_('hang'): 1207, np.str_('hanging'): 1208, np.str_('hansom'): 1209, np.str_('hansoms'): 1210, np.str_('happen'): 1211, np.str_('happened'): 1212, np.str_('happens'): 1213, np.str_('happiness'): 1214, np.str_('happy'): 1215, np.str_('hard'): 1216, np.str_('hardened'): 1217, np.str_('hardly'): 1218, np.str_('hare'): 1219, np.str_('harm'): 1220, np.str_('harmony'): 1221, np.str_('harness'): 1222, np.str_('harsh'): 1223, np.str_('has'): 1224, np.str_('hat'): 1225, np.str_('hauling'): 1226, np.str_('have'): 1227, np.str_('having'): 1228, np.str_('hawklike'): 1229, np.str_('he'): 1230, np.str_('head'): 1231, np.str_('heading'): 1232, np.str_('heads'): 1233, np.str_('hear'): 1234, np.str_('heard'): 1235, np.str_('hearing'): 1236, np.str_('heart'): 1237, np.str_('heartily'): 1238, np.str_('heavier'): 1239, np.str_('heavily'): 1240, np.str_('heavy'): 1241, np.str_('hebrew'): 1242, np.str_('heel'): 1243, np.str_('heels'): 1244, np.str_('height'): 1245, np.str_('held'): 1246, np.str_('help'): 1247, np.str_('helper'): 1248, np.str_('helpless'): 1249, np.str_('hence'): 1250, np.str_('her'): 1251, np.str_('hercules'): 1252, np.str_('here'): 1253, np.str_('hereditary'): 1254, np.str_('herself'): 1255, np.str_('hesitated'): 1256, np.str_('high'): 1257, np.str_('higher'): 1258, np.str_('highest'): 1259, np.str_('highness'): 1260, np.str_('highpower'): 1261, np.str_('him'): 1262, np.str_('himself'): 1263, np.str_('hindrance'): 1264, np.str_('hint'): 1265, np.str_('his'): 1266, np.str_('hoarsely'): 1267, np.str_('hoax'): 1268, np.str_('hobby'): 1269, np.str_('hold'): 1270, np.str_('hole'): 1271, np.str_('holes'): 1272, np.str_('holiday'): 1273, np.str_('holland'): 1274, np.str_('holmes'): 1275, np.str_('home'): 1276, np.str_('homecentred'): 1277, np.str_('honour'): 1278, np.str_('honourable'): 1279, np.str_('hoofs'): 1280, np.str_('hope'): 1281, np.str_('hoped'): 1282, np.str_('hopeless'): 1283, np.str_('hopes'): 1284, np.str_('hopkins'): 1285, np.str_('horses'): 1286, np.str_('horsey'): 1287, np.str_('hot'): 1288, np.str_('hour'): 1289, np.str_('hours'): 1290, np.str_('house'): 1291, np.str_('household'): 1292, np.str_('houses'): 1293, np.str_('hover'): 1294, np.str_('how'): 1295, np.str_('however'): 1296, np.str_('huge'): 1297, np.str_('hum'): 1298, np.str_('human'): 1299, np.str_('humdrum'): 1300, np.str_('humming'): 1301, np.str_('hundred'): 1302, np.str_('hundreds'): 1303, np.str_('hungrily'): 1304, np.str_('hunt'): 1305, np.str_('hunting'): 1306, np.str_('hurled'): 1307, np.str_('hurling'): 1308, np.str_('hurried'): 1309, np.str_('hurriedly'): 1310, np.str_('hurry'): 1311, np.str_('hurrying'): 1312, np.str_('husband'): 1313, np.str_('i'): 1314, np.str_('idea'): 1315, np.str_('ideas'): 1316, np.str_('identify'): 1317, np.str_('identity'): 1318, np.str_('idler'): 1319, np.str_('if'): 1320, np.str_('ignotum'): 1321, np.str_('ii'): 1322, np.str_('iii'): 1323, np.str_('illkempt'): 1324, np.str_('imagination'): 1325, np.str_('imagine'): 1326, np.str_('imbecile'): 1327, np.str_('imitate'): 1328, np.str_('immediate'): 1329, np.str_('immediately'): 1330, np.str_('immense'): 1331, np.str_('immensely'): 1332, np.str_('impatience'): 1333, np.str_('impatiently'): 1334, np.str_('imperial'): 1335, np.str_('imperilled'): 1336, np.str_('implicates'): 1337, np.str_('importance'): 1338, np.str_('important'): 1339, np.str_('impossible'): 1340, np.str_('impression'): 1341, np.str_('improving'): 1342, np.str_('improvisations'): 1343, np.str_('imprudently'): 1344, np.str_('impulse'): 1345, np.str_('in'): 1346, np.str_('inbreath'): 1347, np.str_('inches'): 1348, np.str_('incidents'): 1349, np.str_('incisive'): 1350, np.str_('incites'): 1351, np.str_('inclined'): 1352, np.str_('included'): 1353, np.str_('incognito'): 1354, np.str_('incorrigible'): 1355, np.str_('increased'): 1356, np.str_('indebted'): 1357, np.str_('indeed'): 1358, np.str_('index'): 1359, np.str_('indicated'): 1360, np.str_('indication'): 1361, np.str_('indications'): 1362, np.str_('indirect'): 1363, np.str_('inextricable'): 1364, np.str_('infinitely'): 1365, np.str_('inflamed'): 1366, np.str_('influence'): 1367, np.str_('informality'): 1368, np.str_('information'): 1369, np.str_('informed'): 1370, np.str_('ingenious'): 1371, np.str_('injured'): 1372, np.str_('injuring'): 1373, np.str_('injustice'): 1374, np.str_('ink'): 1375, np.str_('inner'): 1376, np.str_('inquired'): 1377, np.str_('inquiries'): 1378, np.str_('inquiry'): 1379, np.str_('insensibly'): 1380, np.str_('inside'): 1381, np.str_('insist'): 1382, np.str_('inspection'): 1383, np.str_('inspector'): 1384, np.str_('instance'): 1385, np.str_('instant'): 1386, np.str_('instantly'): 1387, np.str_('instead'): 1388, np.str_('instinct'): 1389, np.str_('instructions'): 1390, np.str_('instrument'): 1391, np.str_('insult'): 1392, np.str_('intelligence'): 1393, np.str_('intended'): 1394, np.str_('intention'): 1395, np.str_('interest'): 1396, np.str_('interested'): 1397, np.str_('interesting'): 1398, np.str_('interests'): 1399, np.str_('interfere'): 1400, np.str_('into'): 1401, np.str_('intrigue'): 1402, np.str_('introduce'): 1403, np.str_('introducing'): 1404, np.str_('introspect'): 1405, np.str_('introspective'): 1406, np.str_('intruder'): 1407, np.str_('intrusion'): 1408, np.str_('intrusions'): 1409, np.str_('intrusted'): 1410, np.str_('intuition'): 1411, np.str_('invariable'): 1412, np.str_('invent'): 1413, np.str_('investigation'): 1414, np.str_('inviolate'): 1415, np.str_('inward'): 1416, np.str_('iodoform'): 1417, np.str_('irene'): 1418, np.str_('irishsetter'): 1419, np.str_('iron'): 1420, np.str_('is'): 1421, np.str_('issue'): 1422, np.str_('issues'): 1423, np.str_('it'): 1424, np.str_('italian'): 1425, np.str_('its'): 1426, np.str_('itself'): 1427, np.str_('iv'): 1428, np.str_('ix'): 1429, np.str_('jabez'): 1430, np.str_('jane'): 1431, np.str_('jersey'): 1432, np.str_('jewelbox'): 1433, np.str_('job'): 1434, np.str_('john'): 1435, np.str_('join'): 1436, np.str_('joke'): 1437, np.str_('jones'): 1438, np.str_('jose'): 1439, np.str_('journey'): 1440, np.str_('judgment'): 1441, np.str_('judicial'): 1442, np.str_('jump'): 1443, np.str_('jumped'): 1444, np.str_('just'): 1445, np.str_('keen'): 1446, np.str_('keenly'): 1447, np.str_('keenwitted'): 1448, np.str_('keep'): 1449, np.str_('keeping'): 1450, np.str_('keeps'): 1451, np.str_('kensington'): 1452, np.str_('kept'): 1453, np.str_('key'): 1454, np.str_('kind'): 1455, np.str_('kindliness'): 1456, np.str_('kindly'): 1457, np.str_('kindness'): 1458, np.str_('king'): 1459, np.str_('kingdom'): 1460, np.str_('kings'): 1461, np.str_('knee'): 1462, np.str_('kneecaps'): 1463, np.str_('knees'): 1464, np.str_('knew'): 1465, np.str_('knocked'): 1466, np.str_('knot'): 1467, np.str_('know'): 1468, np.str_('knowing'): 1469, np.str_('knowledge'): 1470, np.str_('known'): 1471, np.str_('knows'): 1472, np.str_('kramm'): 1473, np.str_('la'): 1474, np.str_('labour'): 1475, np.str_('labyrinth'): 1476, np.str_('lady'): 1477, np.str_('laid'): 1478, np.str_('lamps'): 1479, np.str_('landau'): 1480, np.str_('landlady'): 1481, np.str_('landlord'): 1482, np.str_('lane'): 1483, np.str_('langham'): 1484, np.str_('language'): 1485, np.str_('languid'): 1486, np.str_('languor'): 1487, np.str_('lantern'): 1488, np.str_('large'): 1489, np.str_('larger'): 1490, np.str_('last'): 1491, np.str_('late'): 1492, np.str_('lately'): 1493, np.str_('later'): 1494, np.str_('latter'): 1495, np.str_('laugh'): 1496, np.str_('laughed'): 1497, np.str_('laughing'): 1498, np.str_('laughter'): 1499, np.str_('laurel'): 1500, np.str_('lawn'): 1501, np.str_('laws'): 1502, np.str_('lawyer'): 1503, np.str_('lay'): 1504, np.str_('layers'): 1505, np.str_('lead'): 1506, np.str_('leading'): 1507, np.str_('league'): 1508, np.str_('learn'): 1509, np.str_('least'): 1510, np.str_('leather'): 1511, np.str_('leave'): 1512, np.str_('lebanon'): 1513, np.str_('led'): 1514, np.str_('left'): 1515, np.str_('legal'): 1516, np.str_('legs'): 1517, np.str_('lemon'): 1518, np.str_('length'): 1519, np.str_('lengthened'): 1520, np.str_('lengths'): 1521, np.str_('lengthy'): 1522, np.str_('lens'): 1523, np.str_('lenses'): 1524, np.str_('lent'): 1525, np.str_('less'): 1526, np.str_('let'): 1527, np.str_('letter'): 1528, np.str_('letters'): 1529, np.str_('level'): 1530, np.str_('liberty'): 1531, np.str_('license'): 1532, np.str_('lids'): 1533, np.str_('lie'): 1534, np.str_('life'): 1535, np.str_('light'): 1536, np.str_('lighted'): 1537, np.str_('lighting'): 1538, np.str_('lights'): 1539, np.str_('like'): 1540, np.str_('likely'): 1541, np.str_('limbs'): 1542, np.str_('limits'): 1543, np.str_('limp'): 1544, np.str_('line'): 1545, np.str_('lined'): 1546, np.str_('lines'): 1547, np.str_('link'): 1548, np.str_('lip'): 1549, np.str_('lips'): 1550, np.str_('listen'): 1551, np.str_('listened'): 1552, np.str_('lit'): 1553, np.str_('literature'): 1554, np.str_('lithe'): 1555, np.str_('little'): 1556, np.str_('live'): 1557, np.str_('lived'): 1558, np.str_('liver'): 1559, np.str_('lives'): 1560, np.str_('living'): 1561, np.str_('loafer'): 1562, np.str_('loafing'): 1563, np.str_('loathed'): 1564, np.str_('lobster'): 1565, np.str_('locality'): 1566, np.str_('located'): 1567, np.str_('lock'): 1568, np.str_('locked'): 1569, np.str_('lodge'): 1570, np.str_('lodgings'): 1571, np.str_('loftily'): 1572, np.str_('london'): 1573, np.str_('londoners'): 1574, np.str_('long'): 1575, np.str_('longer'): 1576, np.str_('look'): 1577, np.str_('looked'): 1578, np.str_('looking'): 1579, np.str_('lord'): 1580, np.str_('lose'): 1581, np.str_('loss'): 1582, np.str_('lost'): 1583, np.str_('lothman'): 1584, np.str_('loud'): 1585, np.str_('lounged'): 1586, np.str_('loungers'): 1587, np.str_('lounging'): 1588, np.str_('love'): 1589, np.str_('loved'): 1590, np.str_('lovely'): 1591, np.str_('lover'): 1592, np.str_('loves'): 1593, np.str_('low'): 1594, np.str_('lower'): 1595, np.str_('lucky'): 1596, np.str_('luggage'): 1597, np.str_('lunch'): 1598, np.str_('lure'): 1599, np.str_('lurid'): 1600, np.str_('lust'): 1601, np.str_('lying'): 1602, np.str_('machine'): 1603, np.str_('madame'): 1604, np.str_('made'): 1605, np.str_('magistrate'): 1606, np.str_('magnifying'): 1607, np.str_('maid'): 1608, np.str_('main'): 1609, np.str_('maintenance'): 1610, np.str_('majesty'): 1611, np.str_('make'): 1612, np.str_('maker'): 1613, np.str_('makes'): 1614, np.str_('making'): 1615, np.str_('makings'): 1616, np.str_('male'): 1617, np.str_('malignant'): 1618, np.str_('man'): 1619, np.str_('manage'): 1620, np.str_('managed'): 1621, np.str_('manager'): 1622, np.str_('managing'): 1623, np.str_('manner'): 1624, np.str_('mantelpiece'): 1625, np.str_('manual'): 1626, np.str_('manufactory'): 1627, np.str_('many'): 1628, np.str_('march'): 1629, np.str_('mark'): 1630, np.str_('marked'): 1631, np.str_('market'): 1632, np.str_('marks'): 1633, np.str_('marriage'): 1634, np.str_('married'): 1635, np.str_('marry'): 1636, np.str_('mary'): 1637, np.str_('mask'): 1638, np.str_('massive'): 1639, np.str_('master'): 1640, np.str_('masterly'): 1641, np.str_('matter'): 1642, np.str_('matters'): 1643, np.str_('may'): 1644, np.str_('me'): 1645, np.str_('meal'): 1646, np.str_('mean'): 1647, np.str_('meantime'): 1648, np.str_('measures'): 1649, np.str_('medical'): 1650, np.str_('meet'): 1651, np.str_('member'): 1652, np.str_('memory'): 1653, np.str_('men'): 1654, np.str_('menaced'): 1655, np.str_('menendez'): 1656, np.str_('mental'): 1657, np.str_('mention'): 1658, np.str_('mere'): 1659, np.str_('merely'): 1660, np.str_('merit'): 1661, np.str_('merry'): 1662, np.str_('merryweather'): 1663, np.str_('mess'): 1664, np.str_('met'): 1665, np.str_('metal'): 1666, np.str_('method'): 1667, np.str_('methods'): 1668, np.str_('mews'): 1669, np.str_('middle'): 1670, np.str_('midnight'): 1671, np.str_('might'): 1672, np.str_('millionaire'): 1673, np.str_('millions'): 1674, np.str_('mind'): 1675, np.str_('mine'): 1676, np.str_('minute'): 1677, np.str_('minutely'): 1678, np.str_('minutes'): 1679, np.str_('misgivings'): 1680, np.str_('miss'): 1681, np.str_('mission'): 1682, np.str_('mistake'): 1683, np.str_('mistaken'): 1684, np.str_('mister'): 1685, np.str_('mistress'): 1686, np.str_('moist'): 1687, np.str_('moment'): 1688, np.str_('momentary'): 1689, np.str_('monday'): 1690, np.str_('money'): 1691, np.str_('monica'): 1692, np.str_('monogram'): 1693, np.str_('monograph'): 1694, np.str_('month'): 1695, np.str_('months'): 1696, np.str_('mood'): 1697, np.str_('moods'): 1698, np.str_('moody'): 1699, np.str_('mopping'): 1700, np.str_('more'): 1701, np.str_('morning'): 1702, np.str_('mornings'): 1703, np.str_('morris'): 1704, np.str_('mortals'): 1705, np.str_('most'): 1706, np.str_('mostly'): 1707, np.str_('motion'): 1708, np.str_('motioned'): 1709, np.str_('motive'): 1710, np.str_('motives'): 1711, np.str_('mouth'): 1712, np.str_('mouths'): 1713, np.str_('moved'): 1714, np.str_('mr'): 1715, np.str_('mrs'): 1716, np.str_('much'): 1717, np.str_('mud'): 1718, np.str_('mumbling'): 1719, np.str_('murder'): 1720, np.str_('murderer'): 1721, np.str_('murmured'): 1722, np.str_('muscles'): 1723, np.str_('music'): 1724, np.str_('musician'): 1725, np.str_('must'): 1726, np.str_('my'): 1727, np.str_('myself'): 1728, np.str_('mysteries'): 1729, np.str_('mysterious'): 1730, np.str_('mystery'): 1731, np.str_('name'): 1732, np.str_('named'): 1733, np.str_('napoleons'): 1734, np.str_('narrative'): 1735, np.str_('narrow'): 1736, np.str_('narrowly'): 1737, np.str_('naturally'): 1738, np.str_('nature'): 1739, np.str_('near'): 1740, np.str_('nearly'): 1741, np.str_('neat'): 1742, np.str_('necessitate'): 1743, np.str_('neck'): 1744, np.str_('need'): 1745, np.str_('neighbourhood'): 1746, np.str_('neighbours'): 1747, np.str_('neither'): 1748, np.str_('nerves'): 1749, np.str_('nervous'): 1750, np.str_('nest'): 1751, np.str_('neutral'): 1752, np.str_('never'): 1753, np.str_('new'): 1754, np.str_('news'): 1755, np.str_('newspaper'): 1756, np.str_('next'): 1757, np.str_('nice'): 1758, np.str_('nicely'): 1759, np.str_('night'): 1760, np.str_('nine'): 1761, np.str_('nitrate'): 1762, np.str_('no'): 1763, np.str_('noble'): 1764, np.str_('nobleman'): 1765, np.str_('nocturnal'): 1766, np.str_('nod'): 1767, np.str_('nodding'): 1768, np.str_('nominal'): 1769, np.str_('nonconformist'): 1770, np.str_('none'): 1771, np.str_('nor'): 1772, np.str_('north'): 1773, np.str_('norton'): 1774, np.str_('nose'): 1775, np.str_('not'): 1776, np.str_('note'): 1777, np.str_('notebook'): 1778, np.str_('notepaper'): 1779, np.str_('notes'): 1780, np.str_('nothing'): 1781, np.str_('notice'): 1782, np.str_('noticed'): 1783, np.str_('noting'): 1784, np.str_('november'): 1785, np.str_('now'): 1786, np.str_('number'): 1787, np.str_('numerous'): 1788, np.str_('nursegirl'): 1789, np.str_('ne'): 1790, np.str_('obese'): 1791, np.str_('object'): 1792, np.str_('objection'): 1793, np.str_('obliged'): 1794, np.str_('obliging'): 1795, np.str_('observation'): 1796, np.str_('observe'): 1797, np.str_('observed'): 1798, np.str_('observer'): 1799, np.str_('observing'): 1800, np.str_('obstinacy'): 1801, np.str_('obvious'): 1802, np.str_('obviously'): 1803, np.str_('occasion'): 1804, np.str_('occasionally'): 1805, np.str_('occupant'): 1806, np.str_('occupation'): 1807, np.str_('occupied'): 1808, np.str_('occur'): 1809, np.str_('october'): 1810, np.str_('odessa'): 1811, np.str_('of'): 1812, np.str_('off'): 1813, np.str_('office'): 1814, np.str_('officers'): 1815, np.str_('offices'): 1816, np.str_('official'): 1817, np.str_('often'): 1818, np.str_('old'): 1819, np.str_('ominous'): 1820, np.str_('on'): 1821, np.str_('once'): 1822, np.str_('one'): 1823, np.str_('online'): 1824, np.str_('only'): 1825, np.str_('open'): 1826, np.str_('opened'): 1827, np.str_('opening'): 1828, np.str_('opera'): 1829, np.str_('operatic'): 1830, np.str_('opinion'): 1831, np.str_('oppressed'): 1832, np.str_('oppressively'): 1833, np.str_('opulence'): 1834, np.str_('or'): 1835, np.str_('orange'): 1836, np.str_('order'): 1837, np.str_('ordered'): 1838, np.str_('orders'): 1839, np.str_('ordinary'): 1840, np.str_('ormstein'): 1841, np.str_('ornament'): 1842, np.str_('orphanage'): 1843, np.str_('ostlers'): 1844, np.str_('other'): 1845, np.str_('others'): 1846, np.str_('otherwise'): 1847, np.str_('ought'): 1848, np.str_('our'): 1849, np.str_('ourselves'): 1850, np.str_('out'): 1851, np.str_('outlined'): 1852, np.str_('outr'): 1853, np.str_('outside'): 1854, np.str_('outward'): 1855, np.str_('over'): 1856, np.str_('overbright'): 1857, np.str_('overclean'): 1858, np.str_('overcoat'): 1859, np.str_('overpowering'): 1860, np.str_('overprecipitance'): 1861, np.str_('overtopped'): 1862, np.str_('own'): 1863, np.str_('oxford'): 1864, np.str_('paced'): 1865, np.str_('pacing'): 1866, np.str_('pack'): 1867, np.str_('packed'): 1868, np.str_('packet'): 1869, np.str_('paid'): 1870, np.str_('pain'): 1871, np.str_('paint'): 1872, np.str_('pair'): 1873, np.str_('pal'): 1874, np.str_('pale'): 1875, np.str_('palm'): 1876, np.str_('panel'): 1877, np.str_('paper'): 1878, np.str_('papers'): 1879, np.str_('paragraphs'): 1880, np.str_('parallel'): 1881, np.str_('park'): 1882, np.str_('part'): 1883, np.str_('parted'): 1884, np.str_('particularly'): 1885, np.str_('particulars'): 1886, np.str_('partie'): 1887, np.str_('partner'): 1888, np.str_('parts'): 1889, np.str_('party'): 1890, np.str_('pass'): 1891, np.str_('passage'): 1892, np.str_('passed'): 1893, np.str_('passing'): 1894, np.str_('passions'): 1895, np.str_('past'): 1896, np.str_('patch'): 1897, np.str_('patient'): 1898, np.str_('patients'): 1899, np.str_('paused'): 1900, np.str_('pavement'): 1901, np.str_('pawnbroker'): 1902, np.str_('pay'): 1903, np.str_('payday'): 1904, np.str_('peace'): 1905, np.str_('peajacket'): 1906, np.str_('peculiar'): 1907, np.str_('peculiarly'): 1908, np.str_('pedestrians'): 1909, np.str_('peep'): 1910, np.str_('peeped'): 1911, np.str_('peering'): 1912, np.str_('pennsylvania'): 1913, np.str_('penny'): 1914, np.str_('pens'): 1915, np.str_('pensioners'): 1916, np.str_('people'): 1917, np.str_('perceive'): 1918, np.str_('perch'): 1919, np.str_('perched'): 1920, np.str_('perfect'): 1921, np.str_('perfectly'): 1922, np.str_('performer'): 1923, np.str_('perhaps'): 1924, np.str_('person'): 1925, np.str_('personally'): 1926, np.str_('persuaded'): 1927, np.str_('peter'): 1928, np.str_('photograph'): 1929, np.str_('photography'): 1930, np.str_('pick'): 1931, np.str_('picked'): 1932, np.str_('picture'): 1933, np.str_('pictured'): 1934, np.str_('pictures'): 1935, np.str_('piece'): 1936, np.str_('pierced'): 1937, np.str_('piled'): 1938, np.str_('piling'): 1939, np.str_('pinch'): 1940, np.str_('pink'): 1941, np.str_('pinktinted'): 1942, np.str_('pipe'): 1943, np.str_('pips'): 1944, np.str_('pistol'): 1945, np.str_('pitch'): 1946, np.str_('piteous'): 1947, np.str_('pity'): 1948, np.str_('place'): 1949, np.str_('placed'): 1950, np.str_('plainly'): 1951, np.str_('plan'): 1952, np.str_('planet'): 1953, np.str_('planked'): 1954, np.str_('plannings'): 1955, np.str_('plans'): 1956, np.str_('planted'): 1957, np.str_('platitudes'): 1958, np.str_('play'): 1959, np.str_('playing'): 1960, np.str_('plays'): 1961, np.str_('please'): 1962, np.str_('pleased'): 1963, np.str_('pleasure'): 1964, np.str_('plunged'): 1965, np.str_('plunging'): 1966, np.str_('pocket'): 1967, np.str_('pockets'): 1968, np.str_('poetic'): 1969, np.str_('point'): 1970, np.str_('points'): 1971, np.str_('poky'): 1972, np.str_('police'): 1973, np.str_('political'): 1974, np.str_('pompous'): 1975, np.str_('pooh'): 1976, np.str_('poor'): 1977, np.str_('portly'): 1978, np.str_('position'): 1979, np.str_('positions'): 1980, np.str_('positive'): 1981, np.str_('possess'): 1982, np.str_('possibility'): 1983, np.str_('possible'): 1984, np.str_('possibly'): 1985, np.str_('post'): 1986, np.str_('pound'): 1987, np.str_('pounds'): 1988, np.str_('power'): 1989, np.str_('powers'): 1990, np.str_('practical'): 1991, np.str_('practically'): 1992, np.str_('practice'): 1993, np.str_('prague'): 1994, np.str_('pray'): 1995, np.str_('precaution'): 1996, np.str_('preceding'): 1997, np.str_('precious'): 1998, np.str_('precise'): 1999, np.str_('precisely'): 2000, np.str_('predominated'): 2001, np.str_('predominates'): 2002, np.str_('prefer'): 2003, np.str_('prefers'): 2004, np.str_('premises'): 2005, np.str_('preparations'): 2006, np.str_('prepare'): 2007, np.str_('preposterous'): 2008, np.str_('presence'): 2009, np.str_('present'): 2010, np.str_('presented'): 2011, np.str_('presently'): 2012, np.str_('preserve'): 2013, np.str_('press'): 2014, np.str_('presumably'): 2015, np.str_('pretty'): 2016, np.str_('preventing'): 2017, np.str_('price'): 2018, np.str_('prick'): 2019, np.str_('pride'): 2020, np.str_('prima'): 2021, np.str_('prince'): 2022, np.str_('princess'): 2023, np.str_('principal'): 2024, np.str_('principles'): 2025, np.str_('print'): 2026, np.str_('prisoner'): 2027, np.str_('private'): 2028, np.str_('pro'): 2029, np.str_('probable'): 2030, np.str_('probably'): 2031, np.str_('problem'): 2032, np.str_('problems'): 2033, np.str_('proceedings'): 2034, np.str_('process'): 2035, np.str_('processes'): 2036, np.str_('proclaimed'): 2037, np.str_('produce'): 2038, np.str_('produced'): 2039, np.str_('producing'): 2040, np.str_('profession'): 2041, np.str_('programme'): 2042, np.str_('project'): 2043, np.str_('promises'): 2044, np.str_('prompt'): 2045, np.str_('prompted'): 2046, np.str_('promptly'): 2047, np.str_('pronounce'): 2048, np.str_('propagation'): 2049, np.str_('propose'): 2050, np.str_('proposition'): 2051, np.str_('protect'): 2052, np.str_('protruded'): 2053, np.str_('prove'): 2054, np.str_('proves'): 2055, np.str_('provide'): 2056, np.str_('provided'): 2057, np.str_('providing'): 2058, np.str_('provinces'): 2059, np.str_('publicly'): 2060, np.str_('puckered'): 2061, np.str_('puffed'): 2062, np.str_('pull'): 2063, np.str_('pulled'): 2064, np.str_('purely'): 2065, np.str_('purpose'): 2066, np.str_('purposes'): 2067, np.str_('purse'): 2068, np.str_('pursued'): 2069, np.str_('push'): 2070, np.str_('pushed'): 2071, np.str_('put'): 2072, np.str_('putting'): 2073, np.str_('puzzle'): 2074, np.str_('puzzled'): 2075, np.str_('puzzling'): 2076, np.str_('quarrel'): 2077, np.str_('quarter'): 2078, np.str_('quarterpast'): 2079, np.str_('quarters'): 2080, np.str_('queen'): 2081, np.str_('queer'): 2082, np.str_('quench'): 2083, np.str_('quest'): 2084, np.str_('question'): 2085, np.str_('questionable'): 2086, np.str_('questioning'): 2087, np.str_('questions'): 2088, np.str_('quick'): 2089, np.str_('quicker'): 2090, np.str_('quiet'): 2091, np.str_('quietly'): 2092, np.str_('quillpen'): 2093, np.str_('quite'): 2094, np.str_('quitted'): 2095, np.str_('rabbi'): 2096, np.str_('rabbit'): 2097, np.str_('rack'): 2098, np.str_('railedin'): 2099, np.str_('raise'): 2100, np.str_('raised'): 2101, np.str_('raising'): 2102, np.str_('ran'): 2103, np.str_('rang'): 2104, np.str_('ransacked'): 2105, np.str_('rather'): 2106, np.str_('rattled'): 2107, np.str_('reach'): 2108, np.str_('reached'): 2109, np.str_('reaches'): 2110, np.str_('reaction'): 2111, np.str_('read'): 2112, np.str_('readers'): 2113, np.str_('reading'): 2114, np.str_('ready'): 2115, np.str_('readyhanded'): 2116, np.str_('real'): 2117, np.str_('realise'): 2118, np.str_('realism'): 2119, np.str_('realistic'): 2120, np.str_('really'): 2121, np.str_('reason'): 2122, np.str_('reasoned'): 2123, np.str_('reasoner'): 2124, np.str_('reasoning'): 2125, np.str_('reasons'): 2126, np.str_('recall'): 2127, np.str_('receipt'): 2128, np.str_('received'): 2129, np.str_('recent'): 2130, np.str_('recently'): 2131, np.str_('recess'): 2132, np.str_('recognised'): 2133, np.str_('recommence'): 2134, np.str_('recorded'): 2135, np.str_('red'): 2136, np.str_('redder'): 2137, np.str_('redhead'): 2138, np.str_('redheaded'): 2139, np.str_('redheads'): 2140, np.str_('refers'): 2141, np.str_('refreshed'): 2142, np.str_('refreshingly'): 2143, np.str_('refund'): 2144, np.str_('refused'): 2145, np.str_('regain'): 2146, np.str_('regent'): 2147, np.str_('reigning'): 2148, np.str_('rejoiced'): 2149, np.str_('rejoin'): 2150, np.str_('relapsed'): 2151, np.str_('relapsing'): 2152, np.str_('relation'): 2153, np.str_('release'): 2154, np.str_('released'): 2155, np.str_('relentless'): 2156, np.str_('relish'): 2157, np.str_('rely'): 2158, np.str_('remain'): 2159, np.str_('remained'): 2160, np.str_('remaining'): 2161, np.str_('remains'): 2162, np.str_('remark'): 2163, np.str_('remarkable'): 2164, np.str_('remarkably'): 2165, np.str_('remarked'): 2166, np.str_('remember'): 2167, np.str_('remove'): 2168, np.str_('removed'): 2169, np.str_('rending'): 2170, np.str_('reopened'): 2171, np.str_('repaid'): 2172, np.str_('repay'): 2173, np.str_('repeated'): 2174, np.str_('replaced'): 2175, np.str_('report'): 2176, np.str_('reports'): 2177, np.str_('represented'): 2178, np.str_('reproachfully'): 2179, np.str_('reputation'): 2180, np.str_('requirement'): 2181, np.str_('reserve'): 2182, np.str_('resolute'): 2183, np.str_('resolution'): 2184, np.str_('resolve'): 2185, np.str_('resolved'): 2186, np.str_('resource'): 2187, np.str_('resources'): 2188, np.str_('respectable'): 2189, np.str_('responded'): 2190, np.str_('responses'): 2191, np.str_('rest'): 2192, np.str_('restaurant'): 2193, np.str_('rested'): 2194, np.str_('restrictions'): 2195, np.str_('result'): 2196, np.str_('results'): 2197, np.str_('retired'): 2198, np.str_('returned'): 2199, np.str_('returning'): 2200, np.str_('returns'): 2201, np.str_('reuse'): 2202, np.str_('reveal'): 2203, np.str_('revolver'): 2204, np.str_('reward'): 2205, np.str_('rich'): 2206, np.str_('richer'): 2207, np.str_('richness'): 2208, np.str_('ridiculously'): 2209, np.str_('right'): 2210, np.str_('ring'): 2211, np.str_('ringing'): 2212, np.str_('rings'): 2213, np.str_('rise'): 2214, np.str_('risen'): 2215, np.str_('risk'): 2216, np.str_('road'): 2217, np.str_('roadway'): 2218, np.str_('roar'): 2219, np.str_('robbery'): 2220, np.str_('rocket'): 2221, np.str_('rogue'): 2222, np.str_('role'): 2223, np.str_('roll'): 2224, np.str_('rolled'): 2225, np.str_('roof'): 2226, np.str_('roofs'): 2227, np.str_('room'): 2228, np.str_('rooms'): 2229, np.str_('roots'): 2230, np.str_('rose'): 2231, np.str_('ross'): 2232, np.str_('rough'): 2233, np.str_('round'): 2234, np.str_('routine'): 2235, np.str_('row'): 2236, np.str_('royal'): 2237, np.str_('rubbed'): 2238, np.str_('rubber'): 2239, np.str_('rubbing'): 2240, np.str_('rueful'): 2241, np.str_('ruin'): 2242, np.str_('rule'): 2243, np.str_('rules'): 2244, np.str_('rumble'): 2245, np.str_('run'): 2246, np.str_('running'): 2247, np.str_('runs'): 2248, np.str_('rush'): 2249, np.str_('rushed'): 2250, np.str_('rushing'): 2251, np.str_('russian'): 2252, np.str_('sadfaced'): 2253, np.str_('safe'): 2254, np.str_('safeguard'): 2255, np.str_('safely'): 2256, np.str_('safer'): 2257, np.str_('said'): 2258, np.str_('sake'): 2259, np.str_('salary'): 2260, np.str_('sally'): 2261, np.str_('same'): 2262, np.str_('sandwich'): 2263, np.str_('sandwiched'): 2264, np.str_('sardonic'): 2265, np.str_('sat'): 2266, np.str_('satisfaction'): 2267, np.str_('satisfied'): 2268, np.str_('satisfy'): 2269, np.str_('saturday'): 2270, np.str_('savagely'): 2271, np.str_('save'): 2272, np.str_('saved'): 2273, np.str_('saw'): 2274, np.str_('saxecoburg'): 2275, np.str_('saxemeningen'): 2276, np.str_('say'): 2277, np.str_('saying'): 2278, np.str_('says'): 2279, np.str_('scala'): 2280, np.str_('scales'): 2281, np.str_('scandal'): 2282, np.str_('scandinavia'): 2283, np.str_('scarlet'): 2284, np.str_('scattered'): 2285, np.str_('scene'): 2286, np.str_('scent'): 2287, np.str_('science'): 2288, np.str_('scissorsgrinder'): 2289, np.str_('scored'): 2290, np.str_('scores'): 2291, np.str_('scotland'): 2292, np.str_('scott'): 2293, np.str_('scraped'): 2294, np.str_('scratch'): 2295, np.str_('screen'): 2296, np.str_('scribbled'): 2297, np.str_('scuffle'): 2298, np.str_('search'): 2299, np.str_('searched'): 2300, np.str_('searching'): 2301, np.str_('second'): 2302, np.str_('seconds'): 2303, np.str_('secrecy'): 2304, np.str_('secret'): 2305, np.str_('secreted'): 2306, np.str_('secreting'): 2307, np.str_('secretive'): 2308, np.str_('secure'): 2309, np.str_('secured'): 2310, np.str_('securing'): 2311, np.str_('see'): 2312, np.str_('seem'): 2313, np.str_('seemed'): 2314, np.str_('seems'): 2315, np.str_('seen'): 2316, np.str_('seized'): 2317, np.str_('seldom'): 2318, np.str_('selection'): 2319, np.str_('selflighting'): 2320, np.str_('send'): 2321, np.str_('sense'): 2322, np.str_('sensitive'): 2323, np.str_('sent'): 2324, np.str_('separated'): 2325, np.str_('separation'): 2326, np.str_('sequel'): 2327, np.str_('serenely'): 2328, np.str_('serious'): 2329, np.str_('seriously'): 2330, np.str_('serpentine'): 2331, np.str_('serpentinemews'): 2332, np.str_('servant'): 2333, np.str_('services'): 2334, np.str_('set'): 2335, np.str_('settle'): 2336, np.str_('settling'): 2337, np.str_('seven'): 2338, np.str_('sevenandtwenty'): 2339, np.str_('seventeen'): 2340, np.str_('several'): 2341, np.str_('severely'): 2342, np.str_('sex'): 2343, np.str_('shabbily'): 2344, np.str_('shabby'): 2345, np.str_('shabbygenteel'): 2346, np.str_('shade'): 2347, np.str_('shadow'): 2348, np.str_('shag'): 2349, np.str_('shake'): 2350, np.str_('shall'): 2351, np.str_('share'): 2352, np.str_('shared'): 2353, np.str_('sharp'): 2354, np.str_('she'): 2355, np.str_('sheet'): 2356, np.str_('sheets'): 2357, np.str_('shelf'): 2358, np.str_('shelves'): 2359, np.str_('sherlock'): 2360, np.str_('shining'): 2361, np.str_('shiny'): 2362, np.str_('shipwreck'): 2363, np.str_('shock'): 2364, np.str_('shoe'): 2365, np.str_('sholto'): 2366, np.str_('shook'): 2367, np.str_('shooting'): 2368, np.str_('shop'): 2369, np.str_('shops'): 2370, np.str_('short'): 2371, np.str_('shortly'): 2372, np.str_('shot'): 2373, np.str_('should'): 2374, np.str_('shoulder'): 2375, np.str_('shoulderhigh'): 2376, np.str_('shoulders'): 2377, np.str_('shouted'): 2378, np.str_('shouting'): 2379, np.str_('shoving'): 2380, np.str_('show'): 2381, np.str_('showed'): 2382, np.str_('showing'): 2383, np.str_('shown'): 2384, np.str_('shriek'): 2385, np.str_('shrugged'): 2386, np.str_('shut'): 2387, np.str_('shutter'): 2388, np.str_('shutters'): 2389, np.str_('shutting'): 2390, np.str_('sickness'): 2391, np.str_('side'): 2392, np.str_('sidelights'): 2393, np.str_('sides'): 2394, np.str_('sidewhiskered'): 2395, np.str_('sighing'): 2396, np.str_('sight'): 2397, np.str_('sigismond'): 2398, np.str_('sign'): 2399, np.str_('signal'): 2400, np.str_('signature'): 2401, np.str_('signs'): 2402, np.str_('silence'): 2403, np.str_('silent'): 2404, np.str_('silhouette'): 2405, np.str_('silk'): 2406, np.str_('silver'): 2407, np.str_('similar'): 2408, np.str_('simple'): 2409, np.str_('simpleminded'): 2410, np.str_('simplicity'): 2411, np.str_('simplifies'): 2412, np.str_('simplify'): 2413, np.str_('since'): 2414, np.str_('single'): 2415, np.str_('sings'): 2416, np.str_('singular'): 2417, np.str_('sinking'): 2418, np.str_('sir'): 2419, np.str_('sister'): 2420, np.str_('sit'): 2421, np.str_('sitting'): 2422, np.str_('sittingroom'): 2423, np.str_('situation'): 2424, np.str_('six'): 2425, np.str_('size'): 2426, np.str_('skirmishes'): 2427, np.str_('skirts'): 2428, np.str_('slashed'): 2429, np.str_('slavey'): 2430, np.str_('sleeves'): 2431, np.str_('slept'): 2432, np.str_('sleuthhound'): 2433, np.str_('slide'): 2434, np.str_('sliding'): 2435, np.str_('slight'): 2436, np.str_('slim'): 2437, np.str_('slipped'): 2438, np.str_('slipping'): 2439, np.str_('slow'): 2440, np.str_('slowly'): 2441, np.str_('small'): 2442, np.str_('smaller'): 2443, np.str_('smart'): 2444, np.str_('smarter'): 2445, np.str_('smartest'): 2446, np.str_('smasher'): 2447, np.str_('smell'): 2448, np.str_('smelling'): 2449, np.str_('smile'): 2450, np.str_('smiled'): 2451, np.str_('smiling'): 2452, np.str_('smoke'): 2453, np.str_('smokeladen'): 2454, np.str_('smokerocket'): 2455, np.str_('smoking'): 2456, np.str_('smooth'): 2457, np.str_('smoothfaced'): 2458, np.str_('snake'): 2459, np.str_('snapping'): 2460, np.str_('sneer'): 2461, np.str_('snigger'): 2462, np.str_('snuff'): 2463, np.str_('so'): 2464, np.str_('society'): 2465, np.str_('soda'): 2466, np.str_('sofa'): 2467, np.str_('softer'): 2468, np.str_('sole'): 2469, np.str_('solemn'): 2470, np.str_('solemnly'): 2471, np.str_('solicitor'): 2472, np.str_('solved'): 2473, np.str_('some'): 2474, np.str_('someone'): 2475, np.str_('something'): 2476, np.str_('somewhat'): 2477, np.str_('soon'): 2478, np.str_('sooner'): 2479, np.str_('sorry'): 2480, np.str_('sort'): 2481, np.str_('soul'): 2482, np.str_('sound'): 2483, np.str_('sounded'): 2484, np.str_('sounds'): 2485, np.str_('south'): 2486, np.str_('sovereign'): 2487, np.str_('sovereigns'): 2488, np.str_('spare'): 2489, np.str_('spark'): 2490, np.str_('sparkled'): 2491, np.str_('spaulding'): 2492, np.str_('speak'): 2493, np.str_('speaks'): 2494, np.str_('specialist'): 2495, np.str_('specimen'): 2496, np.str_('speckled'): 2497, np.str_('spectacle'): 2498, np.str_('spectators'): 2499, np.str_('spent'): 2500, np.str_('spies'): 2501, np.str_('spinster'): 2502, np.str_('spirit'): 2503, np.str_('spirits'): 2504, np.str_('splash'): 2505, np.str_('splendid'): 2506, np.str_('spoke'): 2507, np.str_('spoken'): 2508, np.str_('sprang'): 2509, np.str_('spread'): 2510, np.str_('sprung'): 2511, np.str_('square'): 2512, np.str_('st'): 2513, np.str_('staffcommander'): 2514, np.str_('stage'): 2515, np.str_('staggered'): 2516, np.str_('stagnant'): 2517, np.str_('stained'): 2518, np.str_('staining'): 2519, np.str_('stair'): 2520, np.str_('stairs'): 2521, np.str_('stake'): 2522, np.str_('stale'): 2523, np.str_('stalls'): 2524, np.str_('stand'): 2525, np.str_('standing'): 2526, np.str_('stands'): 2527, np.str_('stare'): 2528, np.str_('stared'): 2529, np.str_('staring'): 2530, np.str_('start'): 2531, np.str_('started'): 2532, np.str_('starting'): 2533, np.str_('startled'): 2534, np.str_('state'): 2535, np.str_('stately'): 2536, np.str_('states'): 2537, np.str_('station'): 2538, np.str_('stay'): 2539, np.str_('stayathome'): 2540, np.str_('steaming'): 2541, np.str_('steel'): 2542, np.str_('step'): 2543, np.str_('stepped'): 2544, np.str_('steps'): 2545, np.str_('stethoscope'): 2546, np.str_('stick'): 2547, np.str_('sticking'): 2548, np.str_('sticks'): 2549, np.str_('stiff'): 2550, np.str_('still'): 2551, np.str_('stone'): 2552, np.str_('stones'): 2553, np.str_('stood'): 2554, np.str_('stop'): 2555, np.str_('stopped'): 2556, np.str_('stories'): 2557, np.str_('story'): 2558, np.str_('storyteller'): 2559, np.str_('stout'): 2560, np.str_('stoutbuilt'): 2561, np.str_('straight'): 2562, np.str_('strange'): 2563, np.str_('stranger'): 2564, np.str_('strangest'): 2565, np.str_('stream'): 2566, np.str_('streamed'): 2567, np.str_('street'): 2568, np.str_('streets'): 2569, np.str_('strengthen'): 2570, np.str_('stress'): 2571, np.str_('stretch'): 2572, np.str_('stretched'): 2573, np.str_('strict'): 2574, np.str_('strikes'): 2575, np.str_('striking'): 2576, np.str_('strong'): 2577, np.str_('strongly'): 2578, np.str_('struck'): 2579, np.str_('struggle'): 2580, np.str_('struggling'): 2581, np.str_('study'): 2582, np.str_('stupidity'): 2583, np.str_('subduing'): 2584, np.str_('subject'): 2585, np.str_('substitution'): 2586, np.str_('subtle'): 2587, np.str_('suburban'): 2588, np.str_('success'): 2589, np.str_('successful'): 2590, np.str_('successfully'): 2591, np.str_('successive'): 2592, np.str_('succinct'): 2593, np.str_('such'): 2594, np.str_('sudden'): 2595, np.str_('suddenly'): 2596, np.str_('suffer'): 2597, np.str_('sufficed'): 2598, np.str_('sufficient'): 2599, np.str_('suggest'): 2600, np.str_('suggested'): 2601, np.str_('suggestive'): 2602, np.str_('suit'): 2603, np.str_('suited'): 2604, np.str_('suits'): 2605, np.str_('sum'): 2606, np.str_('summons'): 2607, np.str_('sunk'): 2608, np.str_('superb'): 2609, np.str_('superscribed'): 2610, np.str_('suppose'): 2611, np.str_('sure'): 2612, np.str_('surpliced'): 2613, np.str_('surprise'): 2614, np.str_('surprised'): 2615, np.str_('surrounded'): 2616, np.str_('surveyed'): 2617, np.str_('suspected'): 2618, np.str_('suspicion'): 2619, np.str_('suspicious'): 2620, np.str_('sutherland'): 2621, np.str_('swarm'): 2622, np.str_('sweeping'): 2623, np.str_('sweetness'): 2624, np.str_('swiftly'): 2625, np.str_('swing'): 2626, np.str_('sympathetic'): 2627, np.str_('sympathy'): 2628, np.str_('system'): 2629, np.str_('table'): 2630, np.str_('tack'): 2631, np.str_('tags'): 2632, np.str_('take'): 2633, np.str_('taken'): 2634, np.str_('takes'): 2635, np.str_('taking'): 2636, np.str_('tales'): 2637, np.str_('talk'): 2638, np.str_('talking'): 2639, np.str_('tall'): 2640, np.str_('tangled'): 2641, np.str_('tap'): 2642, np.str_('task'): 2643, np.str_('taste'): 2644, np.str_('tattoo'): 2645, np.str_('tattooed'): 2646, np.str_('tearing'): 2647, np.str_('teeth'): 2648, np.str_('teetotaler'): 2649, np.str_('tell'): 2650, np.str_('telling'): 2651, np.str_('temperament'): 2652, np.str_('temple'): 2653, np.str_('temporary'): 2654, np.str_('ten'): 2655, np.str_('tenacious'): 2656, np.str_('tension'): 2657, np.str_('terminated'): 2658, np.str_('terms'): 2659, np.str_('test'): 2660, np.str_('texture'): 2661, np.str_('than'): 2662, np.str_('thank'): 2663, np.str_('thanking'): 2664, np.str_('that'): 2665, np.str_('the'): 2666, np.str_('their'): 2667, np.str_('them'): 2668, np.str_('then'): 2669, np.str_('theoretical'): 2670, np.str_('theories'): 2671, np.str_('theorise'): 2672, np.str_('there'): 2673, np.str_('therefore'): 2674, np.str_('these'): 2675, np.str_('they'): 2676, np.str_('thick'): 2677, np.str_('thief'): 2678, np.str_('thin'): 2679, np.str_('thing'): 2680, np.str_('things'): 2681, np.str_('think'): 2682, np.str_('thinking'): 2683, np.str_('thinks'): 2684, np.str_('third'): 2685, np.str_('thirty'): 2686, np.str_('this'): 2687, np.str_('thoroughfare'): 2688, np.str_('thoroughly'): 2689, np.str_('those'): 2690, np.str_('though'): 2691, np.str_('thought'): 2692, np.str_('thousands'): 2693, np.str_('threatened'): 2694, np.str_('three'): 2695, np.str_('threw'): 2696, np.str_('through'): 2697, np.str_('throughout'): 2698, np.str_('throw'): 2699, np.str_('throwing'): 2700, np.str_('thrown'): 2701, np.str_('thrust'): 2702, np.str_('thrusting'): 2703, np.str_('thumb'): 2704, np.str_('thumped'): 2705, np.str_('thursday'): 2706, np.str_('tide'): 2707, np.str_('tie'): 2708, np.str_('till'): 2709, np.str_('time'): 2710, np.str_('times'): 2711, np.str_('tint'): 2712, np.str_('title'): 2713, np.str_('to'): 2714, np.str_('toast'): 2715, np.str_('tobacco'): 2716, np.str_('tobacconist'): 2717, np.str_('today'): 2718, np.str_('together'): 2719, np.str_('told'): 2720, np.str_('tomorrow'): 2721, np.str_('tonight'): 2722, np.str_('too'): 2723, np.str_('took'): 2724, np.str_('top'): 2725, np.str_('tophat'): 2726, np.str_('tops'): 2727, np.str_('tore'): 2728, np.str_('tossed'): 2729, np.str_('touch'): 2730, np.str_('towards'): 2731, np.str_('town'): 2732, np.str_('track'): 2733, np.str_('tradesman'): 2734, np.str_('traffic'): 2735, np.str_('tragedy'): 2736, np.str_('train'): 2737, np.str_('trained'): 2738, np.str_('tramped'): 2739, np.str_('transferred'): 2740, np.str_('travelled'): 2741, np.str_('tray'): 2742, np.str_('treachery'): 2743, np.str_('treasure'): 2744, np.str_('trepoff'): 2745, np.str_('trick'): 2746, np.str_('tried'): 2747, np.str_('trifle'): 2748, np.str_('trifling'): 2749, np.str_('trimmed'): 2750, np.str_('trincomalee'): 2751, np.str_('triumphant'): 2752, np.str_('trooped'): 2753, np.str_('trousers'): 2754, np.str_('true'): 2755, np.str_('truly'): 2756, np.str_('trust'): 2757, np.str_('trusted'): 2758, np.str_('trustees'): 2759, np.str_('tugged'): 2760, np.str_('tunes'): 2761, np.str_('tunnel'): 2762, np.str_('turn'): 2763, np.str_('turned'): 2764, np.str_('turner'): 2765, np.str_('turning'): 2766, np.str_('turns'): 2767, np.str_('tweedsuited'): 2768, np.str_('twelve'): 2769, np.str_('twentieth'): 2770, np.str_('twenty'): 2771, np.str_('twentyfive'): 2772, np.str_('twentyone'): 2773, np.str_('twice'): 2774, np.str_('twist'): 2775, np.str_('twisted'): 2776, np.str_('two'): 2777, np.str_('twopence'): 2778, np.str_('twostoried'): 2779, np.str_('tying'): 2780, np.str_('ulster'): 2781, np.str_('unacquainted'): 2782, np.str_('unbuttoned'): 2783, np.str_('uncertain'): 2784, np.str_('uncongenial'): 2785, np.str_('uncontrollable'): 2786, np.str_('uncourteous'): 2787, np.str_('undated'): 2788, np.str_('under'): 2789, np.str_('underground'): 2790, np.str_('understand'): 2791, np.str_('unexpected'): 2792, np.str_('unfeigned'): 2793, np.str_('unfortunate'): 2794, np.str_('unique'): 2795, np.str_('united'): 2796, np.str_('unknown'): 2797, np.str_('unless'): 2798, np.str_('unlike'): 2799, np.str_('unlikely'): 2800, np.str_('unmarried'): 2801, np.str_('unnatural'): 2802, np.str_('unofficial'): 2803, np.str_('unpack'): 2804, np.str_('unpleasantness'): 2805, np.str_('until'): 2806, np.str_('unusual'): 2807, np.str_('up'): 2808, np.str_('updated'): 2809, np.str_('upon'): 2810, np.str_('upper'): 2811, np.str_('uproar'): 2812, np.str_('upstairs'): 2813, np.str_('us'): 2814, np.str_('usa'): 2815, np.str_('use'): 2816, np.str_('used'): 2817, np.str_('useful'): 2818, np.str_('using'): 2819, np.str_('usual'): 2820, np.str_('usually'): 2821, np.str_('utmost'): 2822, np.str_('v'): 2823, np.str_('vacancies'): 2824, np.str_('vacancy'): 2825, np.str_('vague'): 2826, np.str_('valley'): 2827, np.str_('value'): 2828, np.str_('values'): 2829, np.str_('vanished'): 2830, np.str_('vanishing'): 2831, np.str_('vary'): 2832, np.str_('vault'): 2833, np.str_('vegetarian'): 2834, np.str_('veil'): 2835, np.str_('veins'): 2836, np.str_('velvet'): 2837, np.str_('verbs'): 2838, np.str_('very'): 2839, np.str_('vex'): 2840, np.str_('vi'): 2841, np.str_('vice'): 2842, np.str_('view'): 2843, np.str_('vigorously'): 2844, np.str_('vii'): 2845, np.str_('viii'): 2846, np.str_('vile'): 2847, np.str_('villa'): 2848, np.str_('vincent'): 2849, np.str_('violinland'): 2850, np.str_('virtue'): 2851, np.str_('visible'): 2852, np.str_('visit'): 2853, np.str_('visitor'): 2854, np.str_('visits'): 2855, np.str_('vital'): 2856, np.str_('vivid'): 2857, np.str_('vizard'): 2858, np.str_('voice'): 2859, np.str_('voices'): 2860, np.str_('volume'): 2861, np.str_('volunteer'): 2862, np.str_('von'): 2863, np.str_('vouching'): 2864, np.str_('vulgar'): 2865, np.str_('vulnerable'): 2866, np.str_('wages'): 2867, np.str_('waistcoat'): 2868, np.str_('waisthigh'): 2869, np.str_('wait'): 2870, np.str_('waited'): 2871, np.str_('waiting'): 2872, np.str_('walk'): 2873, np.str_('walked'): 2874, np.str_('walking'): 2875, np.str_('walks'): 2876, np.str_('wall'): 2877, np.str_('wallenstein'): 2878, np.str_('want'): 2879, np.str_('wanted'): 2880, np.str_('wanting'): 2881, np.str_('wants'): 2882, np.str_('warmly'): 2883, np.str_('warned'): 2884, np.str_('warning'): 2885, np.str_('warnings'): 2886, np.str_('warsaw'): 2887, np.str_('was'): 2888, np.str_('watch'): 2889, np.str_('watchchain'): 2890, np.str_('watched'): 2891, np.str_('watching'): 2892, np.str_('water'): 2893, np.str_('watson'): 2894, np.str_('waved'): 2895, np.str_('waving'): 2896, np.str_('wax'): 2897, np.str_('way'): 2898, np.str_('waylaid'): 2899, np.str_('ways'): 2900, np.str_('we'): 2901, np.str_('weapon'): 2902, np.str_('wear'): 2903, np.str_('wearing'): 2904, np.str_('weary'): 2905, np.str_('weather'): 2906, np.str_('wedged'): 2907, np.str_('weedy'): 2908, np.str_('week'): 2909, np.str_('weeks'): 2910, np.str_('weight'): 2911, np.str_('well'): 2912, np.str_('welldressed'): 2913, np.str_('wellknown'): 2914, np.str_('wellremembered'): 2915, np.str_('went'): 2916, np.str_('were'): 2917, np.str_('west'): 2918, np.str_('wet'): 2919, np.str_('what'): 2920, np.str_('whatever'): 2921, np.str_('whatsoever'): 2922, np.str_('wheel'): 2923, np.str_('wheels'): 2924, np.str_('when'): 2925, np.str_('whence'): 2926, np.str_('where'): 2927, np.str_('whether'): 2928, np.str_('which'): 2929, np.str_('while'): 2930, np.str_('whisky'): 2931, np.str_('whispered'): 2932, np.str_('whistled'): 2933, np.str_('white'): 2934, np.str_('who'): 2935, np.str_('whole'): 2936, np.str_('whom'): 2937, np.str_('whose'): 2938, np.str_('why'): 2939, np.str_('widened'): 2940, np.str_('widower'): 2941, np.str_('wife'): 2942, np.str_('wigs'): 2943, np.str_('wild'): 2944, np.str_('wilhelm'): 2945, np.str_('will'): 2946, np.str_('william'): 2947, np.str_('willing'): 2948, np.str_('wilson'): 2949, np.str_('wind'): 2950, np.str_('winding'): 2951, np.str_('window'): 2952, np.str_('windows'): 2953, np.str_('wire'): 2954, np.str_('wish'): 2955, np.str_('wished'): 2956, np.str_('wishes'): 2957, np.str_('wit'): 2958, np.str_('with'): 2959, np.str_('withdraw'): 2960, np.str_('withdrawn'): 2961, np.str_('within'): 2962, np.str_('without'): 2963, np.str_('witness'): 2964, np.str_('woman'): 2965, np.str_('womanly'): 2966, np.str_('women'): 2967, np.str_('wonder'): 2968, np.str_('wonderful'): 2969, np.str_('wondering'): 2970, np.str_('wooden'): 2971, np.str_('wooing'): 2972, np.str_('word'): 2973, np.str_('words'): 2974, np.str_('wore'): 2975, np.str_('work'): 2976, np.str_('worked'): 2977, np.str_('worker'): 2978, np.str_('working'): 2979, np.str_('world'): 2980, np.str_('worn'): 2981, np.str_('worth'): 2982, np.str_('would'): 2983, np.str_('woven'): 2984, np.str_('wrapped'): 2985, np.str_('wriggled'): 2986, np.str_('wrinkled'): 2987, np.str_('wrist'): 2988, np.str_('wrists'): 2989, np.str_('writers'): 2990, np.str_('writes'): 2991, np.str_('writhing'): 2992, np.str_('writing'): 2993, np.str_('writings'): 2994, np.str_('written'): 2995, np.str_('wronged'): 2996, np.str_('wrote'): 2997, np.str_('wrung'): 2998, np.str_('wwwgutenbergorg'): 2999, np.str_('x'): 3000, np.str_('xi'): 3001, np.str_('xii'): 3002, np.str_('yard'): 3003, np.str_('yawn'): 3004, np.str_('yawning'): 3005, np.str_('year'): 3006, np.str_('years'): 3007, np.str_('yelled'): 3008, np.str_('yellow'): 3009, np.str_('yes'): 3010, np.str_('yet'): 3011, np.str_('you'): 3012, np.str_('young'): 3013, np.str_('your'): 3014, np.str_('yours'): 3015, np.str_('yourself'): 3016, np.str_('yourselves'): 3017, np.str_('youth'): 3018}\n",
            "Unique words[:10]:['a' 'abandoned' 'abbots' 'abhorrent' 'able' 'about' 'above' 'abruptly'\n",
            " 'absence' 'absolute']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Then we need to create sequences of training data**\n",
        " * ## we take ```NPREV_WORDS``` words and predict the next one\n",
        " * ## **We now use the integer encoding for strings, as required by the embedding layer**\n"
      ],
      "metadata": {
        "id": "KyncOE3nC1iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NPREV_WORDS = 5\n",
        "prev_words = []\n",
        "next_word = []\n",
        "for i in range(len(words) - NPREV_WORDS):\n",
        "    seq = [unique_word_index.get(tmp) for tmp in words[i:i + NPREV_WORDS]]\n",
        "    if len(seq)!= NPREV_WORDS:\n",
        "      print(len(seq))\n",
        "    else:\n",
        "      prev_words.append(seq)\n",
        "      # the label\n",
        "      next_word.append(unique_word_index.get(words[i + NPREV_WORDS]))\n",
        "print(prev_words[0:3])\n",
        "print(next_word[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QZ0RHcawdRl",
        "outputId": "c62aeeaf-7aaf-41aa-cd62-3bfc2a8619c5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2043, 1188, 811, 1812, 2666], [1188, 811, 1812, 2666, 45], [811, 1812, 2666, 45, 1812]]\n",
            "[45, 1812, 2360]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(prev_words)\n",
        "X = np.array(prev_words)\n",
        "Y = np.array(next_word)\n",
        "print(f\"X[0][0]:{X[0][0]}\")\n",
        "print(f\"Y[0][0]:{Y[0]}\")\n",
        "print(f\"print(X.shape):{X.shape}\")"
      ],
      "metadata": {
        "id": "CRuMg9Kwr_2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df04c407-2f51-43ab-d214-573238e3987a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X[0][0]:2043\n",
            "Y[0][0]:45\n",
            "print(X.shape):(17101, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the model**\n",
        "* ## To the embedding layer we need to pass the *number of distinct words* $n$ as first argument, the *embedding size* $d$, and the *input sequence length* $N$ (number of temporal steps)\n",
        "* ## The *embedding* layer has an output dimension $N\\times d$, the embedding of all the input words in this temporal window  "
      ],
      "metadata": {
        "id": "SIXjfgpunkLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   remind, the NPREV_WORDS we used now represent the\n",
        "#   numeber of time steps considered in the LSTM recurrence\n",
        "#   so automatically by the LSTM implementation,\n",
        "#   the NPREV_WORDS words are fed to the cell one by one\n",
        "emb_size = 50 # size of the embedding space\n",
        "model = Sequential()\n",
        "nunits = 16 # number of hidden units in LSTMcell\n",
        "model.add(Embedding(tot_uniq_words, emb_size, input_length=NPREV_WORDS))\n",
        "model.add(LSTM(units=nunits))\n",
        "# dense layer stacked atop to classify with softmax\n",
        "model.add(Dense(tot_uniq_words, activation='softmax'))\n",
        "model.build(input_shape=(None, NPREV_WORDS))\n",
        "print(model.summary())\n",
        "model_file = \"NWP_EMB\"+str(emb_size)+\"model\"+str(nunits)+\".weights.h5\"\n",
        "import os\n",
        "if os.path.isfile(model_file):\n",
        "  model.load_weights(model_file)\n",
        "  print(\"file exists, loading\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5*10**-4),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "jqwMg8jl0EBP",
        "outputId": "c7ad6c17-4bf2-4594-df73-3158b08cfed9"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m50\u001b[0m)                 \u001b[38;5;34m150,950\u001b[0m \n",
              "\n",
              " lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      \u001b[38;5;34m4,288\u001b[0m \n",
              "\n",
              " dense_21 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3019\u001b[0m)                   \u001b[38;5;34m51,323\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">150,950</span> \n",
              "\n",
              " lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,288</span> \n",
              "\n",
              " dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3019</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">51,323</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,561\u001b[0m (806.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,561</span> (806.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m206,561\u001b[0m (806.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,561</span> (806.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(model_file):\n",
        "  # training the model\n",
        "\n",
        "  batch_size = 16\n",
        "  epochs = 650\n",
        "  #epochs = 150\n",
        "  history = model.fit(x=X,y=Y,\n",
        "            epochs=epochs,\n",
        "            batch_size = batch_size,\n",
        "            shuffle=True)\n",
        "  # saving the trained weights\n",
        "  model.save_weights(model_file)"
      ],
      "metadata": {
        "id": "VaUJjNlbmlK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f5392e8-43e5-44a3-f8aa-0c544740cff7"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.0508 - loss: 7.1296\n",
            "Epoch 2/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.0552 - loss: 6.1731\n",
            "Epoch 3/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.0583 - loss: 6.0362\n",
            "Epoch 4/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0584 - loss: 5.9968\n",
            "Epoch 5/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.0533 - loss: 5.9365\n",
            "Epoch 6/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0568 - loss: 5.8986\n",
            "Epoch 7/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.0586 - loss: 5.8700\n",
            "Epoch 8/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.0577 - loss: 5.8052\n",
            "Epoch 9/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.0581 - loss: 5.7775\n",
            "Epoch 10/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.0625 - loss: 5.7439\n",
            "Epoch 11/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.0646 - loss: 5.7046\n",
            "Epoch 12/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0674 - loss: 5.6711\n",
            "Epoch 13/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.0771 - loss: 5.5959\n",
            "Epoch 14/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0766 - loss: 5.5580\n",
            "Epoch 15/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0767 - loss: 5.5253\n",
            "Epoch 16/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0761 - loss: 5.4885\n",
            "Epoch 17/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0845 - loss: 5.4201\n",
            "Epoch 18/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.0823 - loss: 5.4096\n",
            "Epoch 19/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.0898 - loss: 5.3771\n",
            "Epoch 20/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0931 - loss: 5.2909\n",
            "Epoch 21/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.0970 - loss: 5.2455\n",
            "Epoch 22/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0973 - loss: 5.2596\n",
            "Epoch 23/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1014 - loss: 5.2077\n",
            "Epoch 24/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.0998 - loss: 5.1362\n",
            "Epoch 25/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1053 - loss: 5.1418\n",
            "Epoch 26/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1095 - loss: 5.0482\n",
            "Epoch 27/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.1067 - loss: 5.0556\n",
            "Epoch 28/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1136 - loss: 4.9957\n",
            "Epoch 29/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1109 - loss: 4.9847\n",
            "Epoch 30/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1158 - loss: 4.9506\n",
            "Epoch 31/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1204 - loss: 4.9031\n",
            "Epoch 32/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1143 - loss: 4.9072\n",
            "Epoch 33/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.1275 - loss: 4.8243\n",
            "Epoch 34/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.1324 - loss: 4.7802\n",
            "Epoch 35/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1328 - loss: 4.7731\n",
            "Epoch 36/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.1382 - loss: 4.7184\n",
            "Epoch 37/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.1375 - loss: 4.7154\n",
            "Epoch 38/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1410 - loss: 4.6637\n",
            "Epoch 39/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.1380 - loss: 4.6844\n",
            "Epoch 40/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1505 - loss: 4.6257\n",
            "Epoch 41/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.1536 - loss: 4.5534\n",
            "Epoch 42/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1560 - loss: 4.5491\n",
            "Epoch 43/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1572 - loss: 4.5505\n",
            "Epoch 44/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1634 - loss: 4.5068\n",
            "Epoch 45/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1682 - loss: 4.4626\n",
            "Epoch 46/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.1629 - loss: 4.4564\n",
            "Epoch 47/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1685 - loss: 4.4516\n",
            "Epoch 48/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.1742 - loss: 4.4092\n",
            "Epoch 49/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1768 - loss: 4.3587\n",
            "Epoch 50/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1836 - loss: 4.3481\n",
            "Epoch 51/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.1837 - loss: 4.3237\n",
            "Epoch 52/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1893 - loss: 4.2657\n",
            "Epoch 53/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.1923 - loss: 4.2511\n",
            "Epoch 54/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.1903 - loss: 4.2392\n",
            "Epoch 55/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.1990 - loss: 4.2222\n",
            "Epoch 56/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1981 - loss: 4.2122\n",
            "Epoch 57/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2015 - loss: 4.1645\n",
            "Epoch 58/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2058 - loss: 4.1589\n",
            "Epoch 59/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.2100 - loss: 4.1089\n",
            "Epoch 60/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2092 - loss: 4.1025\n",
            "Epoch 61/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2122 - loss: 4.1006\n",
            "Epoch 62/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2251 - loss: 4.0265\n",
            "Epoch 63/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.2200 - loss: 4.0472\n",
            "Epoch 64/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.2243 - loss: 4.0085\n",
            "Epoch 65/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2272 - loss: 4.0142\n",
            "Epoch 66/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.2311 - loss: 3.9557\n",
            "Epoch 67/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2450 - loss: 3.9307\n",
            "Epoch 68/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2296 - loss: 3.9219\n",
            "Epoch 69/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2339 - loss: 3.9302\n",
            "Epoch 70/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2534 - loss: 3.8463\n",
            "Epoch 71/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.2402 - loss: 3.8886\n",
            "Epoch 72/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2443 - loss: 3.8564\n",
            "Epoch 73/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.2505 - loss: 3.8270\n",
            "Epoch 74/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.2530 - loss: 3.8242\n",
            "Epoch 75/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2599 - loss: 3.7810\n",
            "Epoch 76/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.2605 - loss: 3.7476\n",
            "Epoch 77/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2691 - loss: 3.7149\n",
            "Epoch 78/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2598 - loss: 3.7196\n",
            "Epoch 79/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2686 - loss: 3.7014\n",
            "Epoch 80/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2647 - loss: 3.7091\n",
            "Epoch 81/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2766 - loss: 3.6512\n",
            "Epoch 82/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.2703 - loss: 3.6842\n",
            "Epoch 83/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2835 - loss: 3.6319\n",
            "Epoch 84/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2822 - loss: 3.6330\n",
            "Epoch 85/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2860 - loss: 3.6043\n",
            "Epoch 86/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2871 - loss: 3.5904\n",
            "Epoch 87/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.2938 - loss: 3.5559\n",
            "Epoch 88/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2999 - loss: 3.5117\n",
            "Epoch 89/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.2989 - loss: 3.5368\n",
            "Epoch 90/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.2950 - loss: 3.5365\n",
            "Epoch 91/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2932 - loss: 3.5203\n",
            "Epoch 92/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2989 - loss: 3.4771\n",
            "Epoch 93/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3074 - loss: 3.4614\n",
            "Epoch 94/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3116 - loss: 3.4600\n",
            "Epoch 95/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3128 - loss: 3.4425\n",
            "Epoch 96/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3084 - loss: 3.4407\n",
            "Epoch 97/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3168 - loss: 3.3896\n",
            "Epoch 98/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3251 - loss: 3.3707\n",
            "Epoch 99/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.3234 - loss: 3.3876\n",
            "Epoch 100/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3226 - loss: 3.3607\n",
            "Epoch 101/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3202 - loss: 3.3538\n",
            "Epoch 102/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3379 - loss: 3.2945\n",
            "Epoch 103/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3340 - loss: 3.3120\n",
            "Epoch 104/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3315 - loss: 3.3154\n",
            "Epoch 105/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.3427 - loss: 3.2838\n",
            "Epoch 106/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3455 - loss: 3.2584\n",
            "Epoch 107/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.3459 - loss: 3.2395\n",
            "Epoch 108/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3435 - loss: 3.2486\n",
            "Epoch 109/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3429 - loss: 3.2349\n",
            "Epoch 110/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.3448 - loss: 3.2354\n",
            "Epoch 111/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3469 - loss: 3.2094\n",
            "Epoch 112/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3551 - loss: 3.1915\n",
            "Epoch 113/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.3570 - loss: 3.1721\n",
            "Epoch 114/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3560 - loss: 3.1704\n",
            "Epoch 115/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.3632 - loss: 3.1317\n",
            "Epoch 116/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3618 - loss: 3.1522\n",
            "Epoch 117/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3586 - loss: 3.1527\n",
            "Epoch 118/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.3655 - loss: 3.1170\n",
            "Epoch 119/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3697 - loss: 3.1082\n",
            "Epoch 120/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.3682 - loss: 3.0997\n",
            "Epoch 121/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.3758 - loss: 3.0819\n",
            "Epoch 122/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3765 - loss: 3.0631\n",
            "Epoch 123/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3812 - loss: 3.0260\n",
            "Epoch 124/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.3866 - loss: 3.0204\n",
            "Epoch 125/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3831 - loss: 3.0180\n",
            "Epoch 126/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3849 - loss: 3.0102\n",
            "Epoch 127/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3839 - loss: 3.0163\n",
            "Epoch 128/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3826 - loss: 3.0179\n",
            "Epoch 129/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.3912 - loss: 2.9937\n",
            "Epoch 130/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.3935 - loss: 2.9718\n",
            "Epoch 131/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4016 - loss: 2.9433\n",
            "Epoch 132/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3941 - loss: 2.9587\n",
            "Epoch 133/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.4003 - loss: 2.9373\n",
            "Epoch 134/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4017 - loss: 2.9316\n",
            "Epoch 135/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.4044 - loss: 2.9242\n",
            "Epoch 136/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4023 - loss: 2.9240\n",
            "Epoch 137/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4056 - loss: 2.9127\n",
            "Epoch 138/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4071 - loss: 2.8976\n",
            "Epoch 139/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4089 - loss: 2.8782\n",
            "Epoch 140/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4137 - loss: 2.8638\n",
            "Epoch 141/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.4108 - loss: 2.8925\n",
            "Epoch 142/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4152 - loss: 2.8518\n",
            "Epoch 143/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4195 - loss: 2.8236\n",
            "Epoch 144/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.4208 - loss: 2.8349\n",
            "Epoch 145/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.4217 - loss: 2.8088\n",
            "Epoch 146/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4184 - loss: 2.8406\n",
            "Epoch 147/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4268 - loss: 2.7943\n",
            "Epoch 148/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4290 - loss: 2.7823\n",
            "Epoch 149/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.4302 - loss: 2.7486\n",
            "Epoch 150/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4344 - loss: 2.7728\n",
            "Epoch 151/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.4318 - loss: 2.7757\n",
            "Epoch 152/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.4385 - loss: 2.7464\n",
            "Epoch 153/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4329 - loss: 2.7408\n",
            "Epoch 154/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.4350 - loss: 2.7302\n",
            "Epoch 155/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.4402 - loss: 2.7141\n",
            "Epoch 156/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4331 - loss: 2.7220\n",
            "Epoch 157/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4460 - loss: 2.7119\n",
            "Epoch 158/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4364 - loss: 2.7260\n",
            "Epoch 159/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4409 - loss: 2.6933\n",
            "Epoch 160/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4449 - loss: 2.7046\n",
            "Epoch 161/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4428 - loss: 2.6947\n",
            "Epoch 162/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4499 - loss: 2.6778\n",
            "Epoch 163/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4543 - loss: 2.6377\n",
            "Epoch 164/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.4461 - loss: 2.6720\n",
            "Epoch 165/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4475 - loss: 2.6675\n",
            "Epoch 166/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4563 - loss: 2.6279\n",
            "Epoch 167/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4497 - loss: 2.6541\n",
            "Epoch 168/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4569 - loss: 2.6059\n",
            "Epoch 169/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4555 - loss: 2.6086\n",
            "Epoch 170/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.4593 - loss: 2.6195\n",
            "Epoch 171/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4587 - loss: 2.6166\n",
            "Epoch 172/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.4631 - loss: 2.5727\n",
            "Epoch 173/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.4638 - loss: 2.5984\n",
            "Epoch 174/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.4602 - loss: 2.6111\n",
            "Epoch 175/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4716 - loss: 2.5502\n",
            "Epoch 176/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.4726 - loss: 2.5615\n",
            "Epoch 177/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4756 - loss: 2.5337\n",
            "Epoch 178/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.4725 - loss: 2.5455\n",
            "Epoch 179/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4765 - loss: 2.5271\n",
            "Epoch 180/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.4761 - loss: 2.5429\n",
            "Epoch 181/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4785 - loss: 2.5260\n",
            "Epoch 182/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.4703 - loss: 2.5527\n",
            "Epoch 183/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4810 - loss: 2.4976\n",
            "Epoch 184/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.4715 - loss: 2.5078\n",
            "Epoch 185/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.4773 - loss: 2.5156\n",
            "Epoch 186/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4873 - loss: 2.4737\n",
            "Epoch 187/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4836 - loss: 2.4727\n",
            "Epoch 188/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.4879 - loss: 2.4808\n",
            "Epoch 189/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4892 - loss: 2.4624\n",
            "Epoch 190/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4921 - loss: 2.4529\n",
            "Epoch 191/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.4891 - loss: 2.4678\n",
            "Epoch 192/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.4947 - loss: 2.4292\n",
            "Epoch 193/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4873 - loss: 2.4530\n",
            "Epoch 194/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4937 - loss: 2.4445\n",
            "Epoch 195/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.4906 - loss: 2.4423\n",
            "Epoch 196/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.4985 - loss: 2.4281\n",
            "Epoch 197/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4962 - loss: 2.4342\n",
            "Epoch 198/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5072 - loss: 2.3986\n",
            "Epoch 199/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5006 - loss: 2.3988\n",
            "Epoch 200/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5017 - loss: 2.3986\n",
            "Epoch 201/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5029 - loss: 2.3893\n",
            "Epoch 202/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5060 - loss: 2.3726\n",
            "Epoch 203/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5014 - loss: 2.3791\n",
            "Epoch 204/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5113 - loss: 2.3549\n",
            "Epoch 205/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5045 - loss: 2.3854\n",
            "Epoch 206/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5048 - loss: 2.3613\n",
            "Epoch 207/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.5077 - loss: 2.3676\n",
            "Epoch 208/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5147 - loss: 2.3479\n",
            "Epoch 209/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5064 - loss: 2.3553\n",
            "Epoch 210/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5116 - loss: 2.3299\n",
            "Epoch 211/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5096 - loss: 2.3662\n",
            "Epoch 212/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.5099 - loss: 2.3575\n",
            "Epoch 213/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5136 - loss: 2.3167\n",
            "Epoch 214/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5235 - loss: 2.2954\n",
            "Epoch 215/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5183 - loss: 2.3068\n",
            "Epoch 216/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5138 - loss: 2.3273\n",
            "Epoch 217/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5249 - loss: 2.2909\n",
            "Epoch 218/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5206 - loss: 2.2961\n",
            "Epoch 219/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5259 - loss: 2.2952\n",
            "Epoch 220/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5245 - loss: 2.2780\n",
            "Epoch 221/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5205 - loss: 2.2906\n",
            "Epoch 222/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5273 - loss: 2.2730\n",
            "Epoch 223/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5231 - loss: 2.2883\n",
            "Epoch 224/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5274 - loss: 2.2574\n",
            "Epoch 225/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5298 - loss: 2.2555\n",
            "Epoch 226/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5280 - loss: 2.2774\n",
            "Epoch 227/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5211 - loss: 2.2808\n",
            "Epoch 228/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5374 - loss: 2.2124\n",
            "Epoch 229/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5253 - loss: 2.2336\n",
            "Epoch 230/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.5401 - loss: 2.2143\n",
            "Epoch 231/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5310 - loss: 2.2304\n",
            "Epoch 232/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5460 - loss: 2.1960\n",
            "Epoch 233/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5405 - loss: 2.1990\n",
            "Epoch 234/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5381 - loss: 2.1951\n",
            "Epoch 235/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5367 - loss: 2.2031\n",
            "Epoch 236/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5332 - loss: 2.2158\n",
            "Epoch 237/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5366 - loss: 2.2025\n",
            "Epoch 238/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5469 - loss: 2.1671\n",
            "Epoch 239/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5414 - loss: 2.1620\n",
            "Epoch 240/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5523 - loss: 2.1417\n",
            "Epoch 241/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5459 - loss: 2.1714\n",
            "Epoch 242/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5426 - loss: 2.1863\n",
            "Epoch 243/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5438 - loss: 2.1664\n",
            "Epoch 244/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5467 - loss: 2.1431\n",
            "Epoch 245/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5397 - loss: 2.1681\n",
            "Epoch 246/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5493 - loss: 2.1273\n",
            "Epoch 247/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5440 - loss: 2.1384\n",
            "Epoch 248/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.5418 - loss: 2.1738\n",
            "Epoch 249/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5482 - loss: 2.1495\n",
            "Epoch 250/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5517 - loss: 2.1355\n",
            "Epoch 251/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5476 - loss: 2.1483\n",
            "Epoch 252/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5496 - loss: 2.1401\n",
            "Epoch 253/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5584 - loss: 2.1125\n",
            "Epoch 254/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5477 - loss: 2.1234\n",
            "Epoch 255/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5556 - loss: 2.1185\n",
            "Epoch 256/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5495 - loss: 2.1154\n",
            "Epoch 257/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5517 - loss: 2.1196\n",
            "Epoch 258/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5597 - loss: 2.0955\n",
            "Epoch 259/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5555 - loss: 2.1030\n",
            "Epoch 260/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5598 - loss: 2.0989\n",
            "Epoch 261/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5581 - loss: 2.1084\n",
            "Epoch 262/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5653 - loss: 2.0604\n",
            "Epoch 263/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5670 - loss: 2.0544\n",
            "Epoch 264/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5628 - loss: 2.0864\n",
            "Epoch 265/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5639 - loss: 2.0690\n",
            "Epoch 266/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.5546 - loss: 2.0924\n",
            "Epoch 267/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5629 - loss: 2.0622\n",
            "Epoch 268/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5591 - loss: 2.0887\n",
            "Epoch 269/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5654 - loss: 2.0584\n",
            "Epoch 270/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5599 - loss: 2.0568\n",
            "Epoch 271/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5677 - loss: 2.0407\n",
            "Epoch 272/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5732 - loss: 2.0183\n",
            "Epoch 273/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5648 - loss: 2.0647\n",
            "Epoch 274/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.5752 - loss: 2.0160\n",
            "Epoch 275/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.5617 - loss: 2.0491\n",
            "Epoch 276/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5700 - loss: 2.0282\n",
            "Epoch 277/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.5674 - loss: 2.0274\n",
            "Epoch 278/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5722 - loss: 2.0277\n",
            "Epoch 279/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5747 - loss: 2.0066\n",
            "Epoch 280/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5816 - loss: 1.9989\n",
            "Epoch 281/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5760 - loss: 2.0237\n",
            "Epoch 282/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5747 - loss: 1.9967\n",
            "Epoch 283/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.5767 - loss: 1.9968\n",
            "Epoch 284/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5759 - loss: 2.0090\n",
            "Epoch 285/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5813 - loss: 1.9720\n",
            "Epoch 286/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5808 - loss: 1.9817\n",
            "Epoch 287/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5747 - loss: 1.9943\n",
            "Epoch 288/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5815 - loss: 1.9642\n",
            "Epoch 289/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5786 - loss: 1.9800\n",
            "Epoch 290/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5811 - loss: 1.9719\n",
            "Epoch 291/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5807 - loss: 1.9841\n",
            "Epoch 292/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5824 - loss: 1.9598\n",
            "Epoch 293/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5879 - loss: 1.9526\n",
            "Epoch 294/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5825 - loss: 1.9719\n",
            "Epoch 295/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5909 - loss: 1.9492\n",
            "Epoch 296/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5856 - loss: 1.9481\n",
            "Epoch 297/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5787 - loss: 1.9812\n",
            "Epoch 298/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5846 - loss: 1.9624\n",
            "Epoch 299/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5852 - loss: 1.9559\n",
            "Epoch 300/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5941 - loss: 1.9205\n",
            "Epoch 301/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5975 - loss: 1.9048\n",
            "Epoch 302/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.5910 - loss: 1.9322\n",
            "Epoch 303/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5928 - loss: 1.9139\n",
            "Epoch 304/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5976 - loss: 1.9006\n",
            "Epoch 305/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5944 - loss: 1.9194\n",
            "Epoch 306/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.5914 - loss: 1.9217\n",
            "Epoch 307/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5897 - loss: 1.9071\n",
            "Epoch 308/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.5946 - loss: 1.9106\n",
            "Epoch 309/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.5956 - loss: 1.8953\n",
            "Epoch 310/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5990 - loss: 1.8669\n",
            "Epoch 311/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5963 - loss: 1.9138\n",
            "Epoch 312/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6001 - loss: 1.9025\n",
            "Epoch 313/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6013 - loss: 1.8845\n",
            "Epoch 314/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.5962 - loss: 1.9073\n",
            "Epoch 315/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6078 - loss: 1.8548\n",
            "Epoch 316/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5974 - loss: 1.8980\n",
            "Epoch 317/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6019 - loss: 1.8801\n",
            "Epoch 318/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6076 - loss: 1.8617\n",
            "Epoch 319/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6056 - loss: 1.8665\n",
            "Epoch 320/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6043 - loss: 1.8594\n",
            "Epoch 321/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6062 - loss: 1.8541\n",
            "Epoch 322/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6071 - loss: 1.8616\n",
            "Epoch 323/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6049 - loss: 1.8689\n",
            "Epoch 324/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6120 - loss: 1.8413\n",
            "Epoch 325/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6033 - loss: 1.8530\n",
            "Epoch 326/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6060 - loss: 1.8524\n",
            "Epoch 327/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6128 - loss: 1.8352\n",
            "Epoch 328/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6047 - loss: 1.8643\n",
            "Epoch 329/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6113 - loss: 1.8447\n",
            "Epoch 330/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.6110 - loss: 1.8440\n",
            "Epoch 331/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.6067 - loss: 1.8301\n",
            "Epoch 332/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6054 - loss: 1.8402\n",
            "Epoch 333/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6279 - loss: 1.7890\n",
            "Epoch 334/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6140 - loss: 1.8320\n",
            "Epoch 335/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6110 - loss: 1.8311\n",
            "Epoch 336/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6186 - loss: 1.7941\n",
            "Epoch 337/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6153 - loss: 1.8140\n",
            "Epoch 338/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6122 - loss: 1.8232\n",
            "Epoch 339/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6124 - loss: 1.8129\n",
            "Epoch 340/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6100 - loss: 1.8249\n",
            "Epoch 341/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6183 - loss: 1.7957\n",
            "Epoch 342/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6036 - loss: 1.8414\n",
            "Epoch 343/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6136 - loss: 1.8005\n",
            "Epoch 344/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6161 - loss: 1.7901\n",
            "Epoch 345/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6179 - loss: 1.8005\n",
            "Epoch 346/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6252 - loss: 1.7524\n",
            "Epoch 347/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6180 - loss: 1.8073\n",
            "Epoch 348/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6190 - loss: 1.7856\n",
            "Epoch 349/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6147 - loss: 1.7917\n",
            "Epoch 350/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6184 - loss: 1.7806\n",
            "Epoch 351/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6260 - loss: 1.7570\n",
            "Epoch 352/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.6162 - loss: 1.7894\n",
            "Epoch 353/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6237 - loss: 1.7664\n",
            "Epoch 354/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6246 - loss: 1.7488\n",
            "Epoch 355/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6179 - loss: 1.7886\n",
            "Epoch 356/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6245 - loss: 1.7628\n",
            "Epoch 357/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6268 - loss: 1.7584\n",
            "Epoch 358/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6264 - loss: 1.7544\n",
            "Epoch 359/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6297 - loss: 1.7467\n",
            "Epoch 360/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6276 - loss: 1.7347\n",
            "Epoch 361/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6256 - loss: 1.7776\n",
            "Epoch 362/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6216 - loss: 1.7660\n",
            "Epoch 363/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6285 - loss: 1.7515\n",
            "Epoch 364/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6275 - loss: 1.7419\n",
            "Epoch 365/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6284 - loss: 1.7493\n",
            "Epoch 366/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6379 - loss: 1.7059\n",
            "Epoch 367/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6302 - loss: 1.7192\n",
            "Epoch 368/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6302 - loss: 1.7389\n",
            "Epoch 369/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6288 - loss: 1.7421\n",
            "Epoch 370/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 1.7288\n",
            "Epoch 371/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6322 - loss: 1.7348\n",
            "Epoch 372/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6334 - loss: 1.7322\n",
            "Epoch 373/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6267 - loss: 1.7339\n",
            "Epoch 374/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6325 - loss: 1.7049\n",
            "Epoch 375/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6406 - loss: 1.6836\n",
            "Epoch 376/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6410 - loss: 1.7025\n",
            "Epoch 377/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6412 - loss: 1.6918\n",
            "Epoch 378/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6352 - loss: 1.7167\n",
            "Epoch 379/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6387 - loss: 1.6927\n",
            "Epoch 380/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6414 - loss: 1.6737\n",
            "Epoch 381/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6348 - loss: 1.6959\n",
            "Epoch 382/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6393 - loss: 1.6872\n",
            "Epoch 383/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6409 - loss: 1.6834\n",
            "Epoch 384/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6443 - loss: 1.6637\n",
            "Epoch 385/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6432 - loss: 1.6920\n",
            "Epoch 386/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6399 - loss: 1.7050\n",
            "Epoch 387/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6448 - loss: 1.6764\n",
            "Epoch 388/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6415 - loss: 1.6904\n",
            "Epoch 389/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6478 - loss: 1.6697\n",
            "Epoch 390/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6409 - loss: 1.6884\n",
            "Epoch 391/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6487 - loss: 1.6463\n",
            "Epoch 392/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.6349 - loss: 1.7053\n",
            "Epoch 393/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6452 - loss: 1.6538\n",
            "Epoch 394/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6495 - loss: 1.6251\n",
            "Epoch 395/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6455 - loss: 1.6694\n",
            "Epoch 396/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6435 - loss: 1.6736\n",
            "Epoch 397/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6474 - loss: 1.6575\n",
            "Epoch 398/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6413 - loss: 1.6808\n",
            "Epoch 399/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6444 - loss: 1.6666\n",
            "Epoch 400/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6433 - loss: 1.6572\n",
            "Epoch 401/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6423 - loss: 1.6747\n",
            "Epoch 402/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6437 - loss: 1.6662\n",
            "Epoch 403/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6477 - loss: 1.6325\n",
            "Epoch 404/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6482 - loss: 1.6395\n",
            "Epoch 405/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6533 - loss: 1.6302\n",
            "Epoch 406/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6454 - loss: 1.6497\n",
            "Epoch 407/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6529 - loss: 1.6114\n",
            "Epoch 408/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6485 - loss: 1.6386\n",
            "Epoch 409/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6507 - loss: 1.6094\n",
            "Epoch 410/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6522 - loss: 1.6292\n",
            "Epoch 411/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6509 - loss: 1.6293\n",
            "Epoch 412/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6508 - loss: 1.6156\n",
            "Epoch 413/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6513 - loss: 1.6400\n",
            "Epoch 414/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6549 - loss: 1.6245\n",
            "Epoch 415/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6582 - loss: 1.5911\n",
            "Epoch 416/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6536 - loss: 1.6179\n",
            "Epoch 417/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6472 - loss: 1.6409\n",
            "Epoch 418/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6561 - loss: 1.6012\n",
            "Epoch 419/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6558 - loss: 1.6074\n",
            "Epoch 420/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6483 - loss: 1.6236\n",
            "Epoch 421/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6483 - loss: 1.6199\n",
            "Epoch 422/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6557 - loss: 1.6020\n",
            "Epoch 423/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6651 - loss: 1.5737\n",
            "Epoch 424/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6577 - loss: 1.5753\n",
            "Epoch 425/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6550 - loss: 1.6142\n",
            "Epoch 426/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6510 - loss: 1.6232\n",
            "Epoch 427/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 1.6093\n",
            "Epoch 428/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6609 - loss: 1.5731\n",
            "Epoch 429/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6608 - loss: 1.5887\n",
            "Epoch 430/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6613 - loss: 1.5748\n",
            "Epoch 431/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6530 - loss: 1.6126\n",
            "Epoch 432/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6615 - loss: 1.5798\n",
            "Epoch 433/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.6589 - loss: 1.5873\n",
            "Epoch 434/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6624 - loss: 1.5737\n",
            "Epoch 435/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6621 - loss: 1.5820\n",
            "Epoch 436/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6594 - loss: 1.5716\n",
            "Epoch 437/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6605 - loss: 1.5694\n",
            "Epoch 438/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6640 - loss: 1.5627\n",
            "Epoch 439/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6610 - loss: 1.5685\n",
            "Epoch 440/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6508 - loss: 1.5972\n",
            "Epoch 441/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6654 - loss: 1.5646\n",
            "Epoch 442/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6677 - loss: 1.5507\n",
            "Epoch 443/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6679 - loss: 1.5516\n",
            "Epoch 444/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6650 - loss: 1.5496\n",
            "Epoch 445/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6599 - loss: 1.5768\n",
            "Epoch 446/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6588 - loss: 1.5870\n",
            "Epoch 447/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6648 - loss: 1.5587\n",
            "Epoch 448/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6647 - loss: 1.5493\n",
            "Epoch 449/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6732 - loss: 1.5332\n",
            "Epoch 450/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6657 - loss: 1.5590\n",
            "Epoch 451/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6649 - loss: 1.5509\n",
            "Epoch 452/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6630 - loss: 1.5487\n",
            "Epoch 453/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6671 - loss: 1.5613\n",
            "Epoch 454/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6698 - loss: 1.5505\n",
            "Epoch 455/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6727 - loss: 1.5105\n",
            "Epoch 456/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6687 - loss: 1.5372\n",
            "Epoch 457/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6679 - loss: 1.5346\n",
            "Epoch 458/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6615 - loss: 1.5671\n",
            "Epoch 459/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6681 - loss: 1.5247\n",
            "Epoch 460/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6643 - loss: 1.5463\n",
            "Epoch 461/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6677 - loss: 1.5411\n",
            "Epoch 462/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6659 - loss: 1.5387\n",
            "Epoch 463/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6765 - loss: 1.5074\n",
            "Epoch 464/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6708 - loss: 1.5361\n",
            "Epoch 465/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6662 - loss: 1.5500\n",
            "Epoch 466/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6645 - loss: 1.5369\n",
            "Epoch 467/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6726 - loss: 1.5265\n",
            "Epoch 468/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6731 - loss: 1.5278\n",
            "Epoch 469/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6729 - loss: 1.5280\n",
            "Epoch 470/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6648 - loss: 1.5426\n",
            "Epoch 471/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6754 - loss: 1.5062\n",
            "Epoch 472/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6701 - loss: 1.5210\n",
            "Epoch 473/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6712 - loss: 1.5265\n",
            "Epoch 474/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6730 - loss: 1.5184\n",
            "Epoch 475/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6698 - loss: 1.5209\n",
            "Epoch 476/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6733 - loss: 1.4962\n",
            "Epoch 477/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6722 - loss: 1.5158\n",
            "Epoch 478/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6775 - loss: 1.4992\n",
            "Epoch 479/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6754 - loss: 1.5096\n",
            "Epoch 480/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.6686 - loss: 1.5049\n",
            "Epoch 481/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6765 - loss: 1.5025\n",
            "Epoch 482/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.6796 - loss: 1.4871\n",
            "Epoch 483/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6761 - loss: 1.5063\n",
            "Epoch 484/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6747 - loss: 1.5174\n",
            "Epoch 485/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6726 - loss: 1.5137\n",
            "Epoch 486/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6755 - loss: 1.5146\n",
            "Epoch 487/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6730 - loss: 1.5037\n",
            "Epoch 488/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6773 - loss: 1.4874\n",
            "Epoch 489/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6786 - loss: 1.4876\n",
            "Epoch 490/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6749 - loss: 1.4832\n",
            "Epoch 491/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6796 - loss: 1.4848\n",
            "Epoch 492/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6816 - loss: 1.4912\n",
            "Epoch 493/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6801 - loss: 1.4664\n",
            "Epoch 494/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6762 - loss: 1.4997\n",
            "Epoch 495/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6750 - loss: 1.4896\n",
            "Epoch 496/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6830 - loss: 1.4695\n",
            "Epoch 497/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6779 - loss: 1.4769\n",
            "Epoch 498/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6798 - loss: 1.4923\n",
            "Epoch 499/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6774 - loss: 1.4793\n",
            "Epoch 500/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6822 - loss: 1.4700\n",
            "Epoch 501/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6807 - loss: 1.4768\n",
            "Epoch 502/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6786 - loss: 1.4766\n",
            "Epoch 503/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6824 - loss: 1.4698\n",
            "Epoch 504/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6762 - loss: 1.4839\n",
            "Epoch 505/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6824 - loss: 1.4740\n",
            "Epoch 506/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6807 - loss: 1.4650\n",
            "Epoch 507/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6841 - loss: 1.4619\n",
            "Epoch 508/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6849 - loss: 1.4650\n",
            "Epoch 509/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6788 - loss: 1.4822\n",
            "Epoch 510/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6832 - loss: 1.4580\n",
            "Epoch 511/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6816 - loss: 1.4576\n",
            "Epoch 512/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 1.4375\n",
            "Epoch 513/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6904 - loss: 1.4332\n",
            "Epoch 514/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.6827 - loss: 1.4593\n",
            "Epoch 515/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6839 - loss: 1.4592\n",
            "Epoch 516/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6841 - loss: 1.4423\n",
            "Epoch 517/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6835 - loss: 1.4521\n",
            "Epoch 518/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6817 - loss: 1.4727\n",
            "Epoch 519/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.6854 - loss: 1.4442\n",
            "Epoch 520/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6880 - loss: 1.4258\n",
            "Epoch 521/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6842 - loss: 1.4341\n",
            "Epoch 522/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6893 - loss: 1.4329\n",
            "Epoch 523/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6877 - loss: 1.4323\n",
            "Epoch 524/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6856 - loss: 1.4464\n",
            "Epoch 525/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6899 - loss: 1.4286\n",
            "Epoch 526/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6845 - loss: 1.4372\n",
            "Epoch 527/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6893 - loss: 1.4223\n",
            "Epoch 528/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6948 - loss: 1.4099\n",
            "Epoch 529/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6879 - loss: 1.4358\n",
            "Epoch 530/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6934 - loss: 1.4165\n",
            "Epoch 531/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6892 - loss: 1.4422\n",
            "Epoch 532/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 1.4055\n",
            "Epoch 533/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6973 - loss: 1.4025\n",
            "Epoch 534/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6910 - loss: 1.4277\n",
            "Epoch 535/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6842 - loss: 1.4494\n",
            "Epoch 536/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6922 - loss: 1.4207\n",
            "Epoch 537/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.6892 - loss: 1.4179\n",
            "Epoch 538/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6949 - loss: 1.4127\n",
            "Epoch 539/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6907 - loss: 1.4201\n",
            "Epoch 540/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6962 - loss: 1.4030\n",
            "Epoch 541/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6913 - loss: 1.4105\n",
            "Epoch 542/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6977 - loss: 1.3982\n",
            "Epoch 543/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6984 - loss: 1.4030\n",
            "Epoch 544/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6943 - loss: 1.4027\n",
            "Epoch 545/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6948 - loss: 1.4025\n",
            "Epoch 546/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6972 - loss: 1.3880\n",
            "Epoch 547/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6910 - loss: 1.4087\n",
            "Epoch 548/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6912 - loss: 1.4021\n",
            "Epoch 549/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6952 - loss: 1.4066\n",
            "Epoch 550/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6981 - loss: 1.4093\n",
            "Epoch 551/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6994 - loss: 1.3832\n",
            "Epoch 552/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6885 - loss: 1.4345\n",
            "Epoch 553/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7006 - loss: 1.3830\n",
            "Epoch 554/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6984 - loss: 1.4132\n",
            "Epoch 555/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7011 - loss: 1.3697\n",
            "Epoch 556/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6959 - loss: 1.3902\n",
            "Epoch 557/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6981 - loss: 1.3799\n",
            "Epoch 558/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6942 - loss: 1.4036\n",
            "Epoch 559/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6899 - loss: 1.4191\n",
            "Epoch 560/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6959 - loss: 1.4053\n",
            "Epoch 561/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7017 - loss: 1.3876\n",
            "Epoch 562/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7008 - loss: 1.3707\n",
            "Epoch 563/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7019 - loss: 1.3643\n",
            "Epoch 564/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6951 - loss: 1.3801\n",
            "Epoch 565/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7091 - loss: 1.3668\n",
            "Epoch 566/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6967 - loss: 1.3973\n",
            "Epoch 567/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6984 - loss: 1.3715\n",
            "Epoch 568/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6992 - loss: 1.3678\n",
            "Epoch 569/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6975 - loss: 1.3682\n",
            "Epoch 570/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7033 - loss: 1.3793\n",
            "Epoch 571/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7029 - loss: 1.3753\n",
            "Epoch 572/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6963 - loss: 1.3751\n",
            "Epoch 573/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7076 - loss: 1.3640\n",
            "Epoch 574/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7000 - loss: 1.3643\n",
            "Epoch 575/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.7019 - loss: 1.3717\n",
            "Epoch 576/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.6944 - loss: 1.3880\n",
            "Epoch 577/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7067 - loss: 1.3522\n",
            "Epoch 578/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6997 - loss: 1.3713\n",
            "Epoch 579/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7090 - loss: 1.3601\n",
            "Epoch 580/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7012 - loss: 1.3764\n",
            "Epoch 581/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6995 - loss: 1.3647\n",
            "Epoch 582/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7042 - loss: 1.3493\n",
            "Epoch 583/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.7059 - loss: 1.3491\n",
            "Epoch 584/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7037 - loss: 1.3461\n",
            "Epoch 585/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6989 - loss: 1.3742\n",
            "Epoch 586/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7088 - loss: 1.3379\n",
            "Epoch 587/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6956 - loss: 1.3868\n",
            "Epoch 588/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7052 - loss: 1.3268\n",
            "Epoch 589/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7004 - loss: 1.3652\n",
            "Epoch 590/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7029 - loss: 1.3595\n",
            "Epoch 591/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7069 - loss: 1.3551\n",
            "Epoch 592/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7084 - loss: 1.3344\n",
            "Epoch 593/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7057 - loss: 1.3460\n",
            "Epoch 594/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7064 - loss: 1.3493\n",
            "Epoch 595/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7087 - loss: 1.3405\n",
            "Epoch 596/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7066 - loss: 1.3346\n",
            "Epoch 597/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7060 - loss: 1.3496\n",
            "Epoch 598/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.7039 - loss: 1.3488\n",
            "Epoch 599/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7149 - loss: 1.3037\n",
            "Epoch 600/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7029 - loss: 1.3462\n",
            "Epoch 601/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7054 - loss: 1.3381\n",
            "Epoch 602/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7068 - loss: 1.3324\n",
            "Epoch 603/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7128 - loss: 1.3285\n",
            "Epoch 604/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7099 - loss: 1.3282\n",
            "Epoch 605/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7093 - loss: 1.3259\n",
            "Epoch 606/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7100 - loss: 1.3148\n",
            "Epoch 607/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7111 - loss: 1.3273\n",
            "Epoch 608/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7065 - loss: 1.3514\n",
            "Epoch 609/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7096 - loss: 1.3307\n",
            "Epoch 610/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7087 - loss: 1.3410\n",
            "Epoch 611/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7105 - loss: 1.3204\n",
            "Epoch 612/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7230 - loss: 1.2972\n",
            "Epoch 613/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7051 - loss: 1.3283\n",
            "Epoch 614/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7074 - loss: 1.3338\n",
            "Epoch 615/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7043 - loss: 1.3560\n",
            "Epoch 616/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7151 - loss: 1.3081\n",
            "Epoch 617/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7164 - loss: 1.2982\n",
            "Epoch 618/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7156 - loss: 1.3095\n",
            "Epoch 619/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7109 - loss: 1.3220\n",
            "Epoch 620/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7082 - loss: 1.3294\n",
            "Epoch 621/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7137 - loss: 1.3197\n",
            "Epoch 622/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7130 - loss: 1.3175\n",
            "Epoch 623/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7148 - loss: 1.3105\n",
            "Epoch 624/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 1.3210\n",
            "Epoch 625/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7190 - loss: 1.2934\n",
            "Epoch 626/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7142 - loss: 1.3134\n",
            "Epoch 627/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.7142 - loss: 1.3010\n",
            "Epoch 628/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7063 - loss: 1.3175\n",
            "Epoch 629/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7153 - loss: 1.3133\n",
            "Epoch 630/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7164 - loss: 1.3013\n",
            "Epoch 631/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7223 - loss: 1.2832\n",
            "Epoch 632/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7116 - loss: 1.3129\n",
            "Epoch 633/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 1.2851\n",
            "Epoch 634/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7213 - loss: 1.2654\n",
            "Epoch 635/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7145 - loss: 1.3072\n",
            "Epoch 636/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7173 - loss: 1.2793\n",
            "Epoch 637/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7162 - loss: 1.2899\n",
            "Epoch 638/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7148 - loss: 1.3011\n",
            "Epoch 639/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7149 - loss: 1.3058\n",
            "Epoch 640/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 1.3019\n",
            "Epoch 641/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 1.2878\n",
            "Epoch 642/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7095 - loss: 1.3056\n",
            "Epoch 643/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7142 - loss: 1.3082\n",
            "Epoch 644/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.7237 - loss: 1.2783\n",
            "Epoch 645/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7159 - loss: 1.2886\n",
            "Epoch 646/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7205 - loss: 1.2764\n",
            "Epoch 647/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 1.2902\n",
            "Epoch 648/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7147 - loss: 1.3043\n",
            "Epoch 649/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7184 - loss: 1.3008\n",
            "Epoch 650/650\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7154 - loss: 1.2931\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=NWP_EMB50model16.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-9d68a69f060e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             shuffle=True)\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# saving the trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=NWP_EMB50model16.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"NWP_EMB50model16.weights.h5\"\n",
        "model.save_weights(model_file)"
      ],
      "metadata": {
        "id": "50cwGqclEFbS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With embedding we did not reach a pleateau, more training epochs likely to be necessary\n",
        "* ## The increased number of parameters need more training epochs, and in general specific refinements"
      ],
      "metadata": {
        "id": "BEirImVmIa_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bidirectional RNNs**\n",
        "* ## In Keras we can implement a bidirection RNN using a ```Bidirectional``` layer ([docs](https://keras.io/api/layers/recurrent_layers/bidirectional/))"
      ],
      "metadata": {
        "id": "UfIFurmKMfqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "keras.layers.Bidirectional(\n",
        "\n",
        ">layer,\n",
        "\n",
        ">merge_mode=\"concat\",\n",
        "\n",
        ">weights=None,\n",
        "\n",
        ">backward_layer=None, **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "t9wptmNUMnmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main arguments\n",
        "> * ### **layer**: keras.layers.RNN instance, such as keras.layers.LSTM or keras.layers.GRU. Should be a sequence-processing layer\n",
        "> * ### **merge_mode**: Mode by which outputs of the forward and backward RNNs will be combined. One of {\"sum\", \"mul\", \"concat\", \"ave\", None}. Defaults to \"concat\".\n",
        "> * ### **backward_layer**: Optional keras.layers.RNN, or keras.layers.Layer instance to be used to handle backwards input processing.\n",
        ">> * #### If backward_layer is not provided, the layer instance passed as the layer argument will be used to generate the backward layer automatically.\n",
        ">> * #### Can be different than ```layer``` (see docs)"
      ],
      "metadata": {
        "id": "WyIy6MxUMoRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We first prepare re-process the data so as to use one-hot encoding instead of embedding layers (like in the previous lecture)"
      ],
      "metadata": {
        "id": "5kWpdzgCG7CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding,Dense, Bidirectional, Input\n",
        "import tensorflow as tf\n",
        "\n",
        "path = '1661-0.txt'\n",
        "text = open(path).read().lower()\n",
        "max_size=100000\n",
        "# cutting text due to memory size limitations\n",
        "text = text[:max_size]\n",
        "print('selected length, number of characters:', len(text))\n",
        "\n",
        "import string\n",
        "def get_words(text):\n",
        "  text = text.replace('--', ' ')\n",
        "  # split into tokens by white space\n",
        "  words = text.split()\n",
        "  # remove punctuation from each token\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  words = [w.translate(table) for w in words]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in words if word.isalpha()]\n",
        "  # make lower case\n",
        "  words = [word.lower() for word in words]\n",
        "  return words\n",
        "\n",
        "words = get_words(text)\n",
        "tot_uniq_words =  len(set(words))\n",
        "print(words[:200])\n",
        "print(f\"Total words: {len(words)}\")\n",
        "print(f\"Unique words: {tot_uniq_words}\")\n",
        "\n",
        "NPREV_WORDS = 5\n",
        "prev_words = []\n",
        "next_word = []\n",
        "for i in range(len(words) - NPREV_WORDS):\n",
        "    seq = words[i:i + NPREV_WORDS]\n",
        "    if len(seq)!= NPREV_WORDS:\n",
        "      print(len(seq))\n",
        "    else:\n",
        "      prev_words.append(seq)\n",
        "      # the label\n",
        "      next_word.append(words[i + NPREV_WORDS])\n",
        "print(prev_words[0:3])\n",
        "print(next_word[0:3])\n",
        "\n",
        "X = np.zeros((len(prev_words), NPREV_WORDS, tot_uniq_words), dtype=bool)\n",
        "Y = np.zeros((len(next_word), tot_uniq_words), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1 # position for the one-hot\n",
        "    Y[i, unique_word_index[next_word[i]]] = 1\n",
        "\n",
        "print(f\"X[0][0]:{X[0][0]}\")\n",
        "print(f\"Y[0][0]:{Y[0]}\")\n",
        "print(f\"print(X.shape):{X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trdFfP3eWlA0",
        "outputId": "7d52cfb2-e323-4cf6-8908-356bfe25b889"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selected length, number of characters: 100000\n",
            "['project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'wwwgutenbergorg', 'if', 'you', 'are', 'not', 'located', 'in', 'the', 'united', 'states', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'ebook', 'title', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'author', 'arthur', 'conan', 'doyle', 'release', 'date', 'november', 'ebook', 'most', 'recently', 'updated', 'october', 'language', 'english', 'character', 'set', 'encoding', 'produced', 'by', 'an', 'anonymous', 'project', 'gutenberg', 'volunteer', 'and', 'jose', 'menendez', 'start', 'of', 'the', 'project', 'gutenberg', 'ebook', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'contents', 'i', 'a', 'scandal', 'in', 'bohemia', 'ii', 'the', 'redheaded', 'league', 'iii', 'a', 'case', 'of', 'identity', 'iv', 'the', 'boscombe', 'valley', 'mystery', 'v', 'the', 'five', 'orange', 'pips', 'vi', 'the', 'man', 'with', 'the', 'twisted', 'lip', 'vii', 'the', 'adventure', 'of', 'the', 'blue', 'carbuncle', 'viii', 'the', 'adventure', 'of', 'the', 'speckled', 'band', 'ix', 'the', 'adventure', 'of', 'the', 'thumb']\n",
            "Total words: 17106\n",
            "Unique words: 3019\n",
            "[['project', 'gutenberg', 'ebook', 'of', 'the'], ['gutenberg', 'ebook', 'of', 'the', 'adventures'], ['ebook', 'of', 'the', 'adventures', 'of']]\n",
            "['adventures', 'of', 'sherlock']\n",
            "X[0][0]:[False False False ... False False False]\n",
            "Y[0][0]:[False False False ... False False False]\n",
            "print(X.shape):(17101, 5, 3019)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the Bidirectional model**\n",
        "* ## Use a similar number of parameters used for the one directional one\n",
        "* ## Since it has two \"parallel\" RNN models, to keep the same number of parameters, we need to half the hidden state dimension"
      ],
      "metadata": {
        "id": "y3an_wjNXpw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nhunits = 8\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(NPREV_WORDS, tot_uniq_words)))\n",
        "model.add(Bidirectional(LSTM(units=nhunits)))\n",
        "# dense layer stacked atop to classify with softmax\n",
        "model.add(Dense(tot_uniq_words, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "model_file = \"NWP_LSTM\"+str(nhunits)+\"_BIDIR.weights.h5\"\n",
        "import os\n",
        "to_train=True\n",
        "if os.path.isfile(model_file):\n",
        "  to_train= False\n",
        "  model.load_weights(model_file)\n",
        "  print(\"file exists, loading\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5*10**-4),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "FqWUXzqbXyVD",
        "outputId": "e561d8d0-beb7-4f91-e921-219b7b162dca"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                    \u001b[38;5;34m193,792\u001b[0m \n",
              "\n",
              " dense_23 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3019\u001b[0m)                   \u001b[38;5;34m51,323\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">193,792</span> \n",
              "\n",
              " dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3019</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">51,323</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m245,115\u001b[0m (957.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,115</span> (957.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m245,115\u001b[0m (957.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,115</span> (957.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "file exists, loading\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(model_file):\n",
        "  # train the model\n",
        "  batch_size = 16\n",
        "  epochs = 650\n",
        "  #epochs = 150\n",
        "  history = model.fit(x=X,y=Y,\n",
        "            epochs=epochs,\n",
        "            batch_size = batch_size,\n",
        "            shuffle=True)\n",
        "  # saving the trained weights\n",
        "  model.save_weights(model_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "x32ngNoPZcJs"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"bidirectional.weights.h5\"\n",
        "model.save_weights(model_file)"
      ],
      "metadata": {
        "id": "39c7QmqiAz2j"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file2 = \"drive/MyDrive/lecture-13a/bidirectional.weights.h5\"\n",
        "model.save_weights(model_file2)"
      ],
      "metadata": {
        "id": "pcYhLyF-DMhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the model to reconstruct a text**\n",
        "* ## Measure the performance as accuracy in predicting the next word"
      ],
      "metadata": {
        "id": "4n-cPD4kHhlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transorm the input \"text\" in one samples formed by its words.\n",
        "# \"text\" should contain NPREV_WORDS words\n",
        "def prepare_input(text, NPREV_WORDS, tot_uniq_words, word_dict):\n",
        "    x = np.zeros((1, NPREV_WORDS, tot_uniq_words))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        word = word.lower()\n",
        "        if word not in word_dict:\n",
        "          print(f\"word:{word} not in dictionary!\")\n",
        "          exit()\n",
        "        # stop when number of time steps reached\n",
        "        if t >= NPREV_WORDS:\n",
        "          break\n",
        "        else:\n",
        "          x[0, t, word_dict[word]] = 1\n",
        "    return x\n",
        "\n",
        "# input text to be predicted, the dictionary of words on which the model has\n",
        "# been trained\n",
        "def predict_completion(model, text, NPREV_WORDS, tot_uniq_words, word_dict):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    next_word = ''\n",
        "    x = prepare_input(text, NPREV_WORDS, tot_uniq_words, word_dict)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    #print(f\"preds.shape:{preds.shape}\")\n",
        "    # taking next word as the one with maximum probability\n",
        "    #  should be extracted\n",
        "    next_index = np.argmax(preds)\n",
        "    next_word = list(word_dict.keys())[list(word_dict.values()).index(next_index)]\n",
        "    return next_word\n",
        "\n",
        "# number of words to recontstuct\n",
        "recon_len = 500\n",
        "ini = 190 # postion in the input text Where a whole sentence starts.\n",
        "\n",
        "test = words[ini:ini+NPREV_WORDS]\n",
        "# concatenate string list into a text separated\n",
        "test_text = \" \".join(test)\n",
        "print(f\"initial text: {test_text}\")\n",
        "recon_text = []\n",
        "# recontructing text with the predicted words in sequence, then compare with the true text\n",
        "for i in range(recon_len):\n",
        "  recon_text.append(predict_completion(model, test_text, NPREV_WORDS, tot_uniq_words, unique_word_index))\n",
        "  test[:NPREV_WORDS-1] = test[1:NPREV_WORDS]\n",
        "  test[NPREV_WORDS-1] = words[ini+i+NPREV_WORDS]\n",
        "  test_text = \" \".join(test)\n",
        "\n",
        "real_text = words[ini+NPREV_WORDS:ini+NPREV_WORDS+recon_len]\n",
        "accuracy = np.sum([1 if recon_text[i]== real_text[i] else 0 for i in range(recon_len)])/recon_len\n",
        "## Visual check\n",
        "print(f\"real text:{words[ini+NPREV_WORDS:ini+15+NPREV_WORDS]}\")\n",
        "print(f\"recon_text:{recon_text[:15]}\")\n",
        "print(f\"Total accuracy:{accuracy}\")"
      ],
      "metadata": {
        "id": "kB6wGav9Hfy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ec49b6-4d78-4b83-c347-4b731d7039f0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial text: of the speckled band ix\n",
            "real text:['the', 'adventure', 'of', 'the', 'thumb', 'x', 'the', 'adventure', 'of', 'the', 'noble', 'bachelor', 'xi', 'the', 'adventure']\n",
            "recon_text:[np.str_('the'), np.str_('adventure'), np.str_('of'), np.str_('the'), np.str_('speckled'), np.str_('x'), np.str_('the'), np.str_('adventure'), np.str_('of'), np.str_('the'), np.str_('noble'), np.str_('bachelor'), np.str_('xi'), np.str_('the'), np.str_('adventure')]\n",
            "Total accuracy:0.956\n"
          ]
        }
      ]
    }
  ]
}