{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professor provided the dataset in the file diabetes.csv altho I found the [same dataset here](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input # dense is a fully connected layer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/diabetes.csv')\n",
    "print(data.isnull().sum())\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Outcome']\n",
    "X = data.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Non-Diabetics\n",
      "268 Diabetics\n"
     ]
    }
   ],
   "source": [
    "col_names = X.columns.values.tolist()\n",
    "print(f\"{(Y==0).sum()} Non-Diabetics\")\n",
    "print(f\"{(Y==1).sum()} Diabetics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sscaler = StandardScaler()\n",
    "mmscaler = MinMaxScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Rest', sscaler, col_names[:-1]),\n",
    "        ('Age', mmscaler, ['Age'])\n",
    "    ],\n",
    "    verbose_feature_names_out = False\n",
    ")\n",
    "col_names[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: 8, num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)  # for reproducibility\n",
    "tf.random.set_seed(123)\n",
    "input_shape= X.shape[1]\n",
    "print(f\"input_shape: {input_shape}, num_classes: {len(np.unique(Y))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    nhid1, nhid2,\n",
    "    learning_rate= 10**-2,\n",
    "    loss='BinaryCrossentropy',\n",
    "    hid_act='relu',\n",
    "    out_act='sigmoid',\n",
    "    dropout_rate=0,\n",
    "    weight_reg=None\n",
    "    # nhid1: number of hidden neurons in the first hidden layer\n",
    "    # nhid2: number of hidden neurons in the second hidden layer\n",
    "    # learning_rate: the learning rate to be used by the optimizer\n",
    "    # loss: loss function to be used\n",
    "    # hid_act: activation function for hidden layers\n",
    "    # out_act: activation function for output layer\n",
    "    # dropout_rate: the rate of dropout to be used\n",
    "    ):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(input_shape,)))  # Explicit Input layer\n",
    "\n",
    "        model.add(Dense( # First hidden layer\n",
    "                    nhid1,\n",
    "                    activation=hid_act,\n",
    "                    kernel_regularizer=weight_reg))\n",
    "        \n",
    "        # set dropout regularization\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(nhid2, # Second hidden layer\n",
    "                        activation=hid_act,\n",
    "                        kernel_regularizer=weight_reg))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1, activation=out_act)) # Output layer\n",
    "        model.compile(loss=loss,\n",
    "                optimizer=SGD(learning_rate=learning_rate),\n",
    "                metrics=['accuracy'])\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class for scikit-learn API\n",
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    nhid1=64, # These are arguments to create_model\n",
    "    nhid2=32,\n",
    "    epochs=50)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.1,shuffle=True, stratify=Y)\n",
    "\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train),columns=col_names)\n",
    "X_test  = pd.DataFrame(preprocessor.transform(X_test),columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Accuracy: 0.8441558441558441\n",
      "F1: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "# These are the scikit-learn fit and predict methods.\n",
    "# Learning the model on all data:\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "model.fit(X_train, Y_train, verbose=0) # Delete verbose=0 to see the training metrics per epoch\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_labels = (pred >= threshold).astype(int)\n",
    "# Test performance\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, pred)}\")\n",
    "print(f\"F1: {f1_score(Y_test, pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "            model=create_model,\n",
    "            nhid1=100, # These are arguments to create_model\n",
    "            nhid2=50,\n",
    "            epochs=50)\n",
    "\n",
    "nhid1 = [64, 32]\n",
    "nhid2 = [32, 16]\n",
    "lr = [10**-2, 10**-1]\n",
    "\n",
    "weight_reg = [None, 'l2']\n",
    "hid_act = ['relu'] # not tuned to reduce the number of combinations\n",
    "batch_size = [32] # not tuned to reduce the number of combinations\n",
    "dropout = [0]\n",
    "loss = ['BinaryCrossentropy'] # not tuned to reduce the number of combinations\n",
    "\n",
    "# Dictionary names must start with model__, if it is an argument of the model, followed by the model argument name.\n",
    "param_grid = dict(\n",
    "                model__nhid1= nhid1,\n",
    "                model__nhid2= nhid2,\n",
    "                model__learning_rate= lr,\n",
    "                model__weight_reg= weight_reg,\n",
    "                model__hid_act= hid_act,\n",
    "                batch_size=batch_size,\n",
    "                model__dropout_rate= dropout,\n",
    "                model__loss= loss,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Best score: 0.412028 using params: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 32, 'model__weight_reg': None}\n",
      "0.38255198720315 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 32, 'model__weight_reg': None}\n",
      "0.36161499817574577 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 32, 'model__weight_reg': 'l2'}\n",
      "0.22908860780714327 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 16, 'model__weight_reg': None}\n",
      "0.335121221707745 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 16, 'model__weight_reg': 'l2'}\n",
      "0.41202808032076327 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 32, 'model__weight_reg': None}\n",
      "0.39683037269244165 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 32, 'model__weight_reg': 'l2'}\n",
      "0.3351628787878788 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 16, 'model__weight_reg': None}\n",
      "0.1677991122435567 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.01, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 16, 'model__weight_reg': 'l2'}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 32, 'model__weight_reg': None}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 32, 'model__weight_reg': 'l2'}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 16, 'model__weight_reg': None}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 64, 'model__nhid2': 16, 'model__weight_reg': 'l2'}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 32, 'model__weight_reg': None}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 32, 'model__weight_reg': 'l2'}\n",
      "0.017205017205017204 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 16, 'model__weight_reg': None}\n",
      "0.0 \t with: {'batch_size': 32, 'model__dropout_rate': 0, 'model__hid_act': 'relu', 'model__learning_rate': 0.1, 'model__loss': 'BinaryCrossentropy', 'model__nhid1': 32, 'model__nhid2': 16, 'model__weight_reg': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, shuffle=True, stratify=Y)\n",
    "\n",
    "X_train = pd.DataFrame(preprocessor.transform(X_train) ,columns=col_names)\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test), columns=col_names)\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "            estimator=model, \n",
    "            param_grid=param_grid,\n",
    "            n_jobs=1,\n",
    "            scoring='f1',\n",
    "            cv=3,\n",
    "            verbose=0\n",
    "            )\n",
    "\n",
    "grid_result = GS.fit(X_train, Y_train, verbose=0) \n",
    "\n",
    "# Best result\n",
    "print(\"Best score: %f using params: %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout test performance\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "test  F1:0.6153846153846154\n",
      "test  Accuracy:0.7844827586206896\n"
     ]
    }
   ],
   "source": [
    "print(\"Holdout test performance\")\n",
    "model = GS.best_estimator_\n",
    "Y_test_predicted = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "Y_test_predicted = (Y_test_predicted >= threshold).astype(int)\n",
    "print(f\"test  F1:{f1_score(Y_test, Y_test_predicted)}\")\n",
    "print(f\"test  Accuracy:{accuracy_score(Y_test, Y_test_predicted)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
