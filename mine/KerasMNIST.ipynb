{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras MNIST\n",
    "The idea is to create a neural network (MLP) with Keras to solve the MNIST classification. Then we can solve the exercise provided by the professor at lecture 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the shape of the data to see what are its dimentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "X_test.shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the shape of our data, we get a 3D tensor. Which means our dataset is a _\"list of matrices\"_ , each sample is a matrix of 28x28.\n",
    "\n",
    "<img src=\"images/tensors.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP take vectors as inputs, so we need to reshape the samples into vector instead of matrices. Also Keras needs float32 inputs, so we need to change the data from uint8 (byte) to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 784)\n",
      "X_test.shape: (10000, 784)\n",
      "X_train.dtype: float32\n",
      "X_train.dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(f\"X_train.dtype: {X_train.dtype}\")\n",
    "print(f\"X_train.dtype: {X_train.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sequential model**: A way to build neural networks in Keras layer by layer, in order.\n",
    "- It creates a **Feedforward Neural Network (FFNN)**.\n",
    "- It’s a **linear stack of layers**, meaning each layer has one input and one output.\n",
    "- Perfect for models like **MLPs** (Multi-Layer Perceptrons).\n",
    "\n",
    "*If your network flows from input to output in a straight line, use Sequential.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense is the type of neural network layer we use in MLPs where:\n",
    "- Every neuron is connected to every neuron in the previous layer\n",
    "- Also called a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (labels): 10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"Number of classes (labels): {num_classes}\") # 10 one for each digit (0 to 9)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential([\n",
    "    # First hidden layer. Input data with size 28*28 and output size 256\n",
    "    #   256 means you set up this layer with 256 hidden neurons.\n",
    "    #   Such a value is up to you, typically a hyper-parameter\n",
    "    # input_shape must be specified just for the first hidden layer\n",
    "    # in (28*28,) the comma indicates the dimension of the batches,\n",
    "    #     unknowkn during the implementation\n",
    "    Dense(256, input_shape=(28*28,), activation='sigmoid'),\n",
    "\n",
    "    # Second hidden layer. Input data with size 256,\n",
    "    #    which were same to output of the first hidden layer.\n",
    "    #    output size 128, we set up 128 neurons  in this hidden layer.\n",
    "    # No need to give input size here because keras gets it automatically.\n",
    "    Dense(800, activation='sigmoid'),\n",
    "\n",
    "    # Output layer. the number of output should be your number\n",
    "    #    of classification\n",
    "    # Softmax for multiclass classification\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an alternative way to do the same, where we define the model and then use the `add()` method to add layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_shape=(28*28,), activation='sigmoid'))\n",
    "# model.add(Dense(128, activation='sigmoid'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third alternative is to use the `tensorflow.keras.Model` class, along with a `tensorflow.keras.input` class.\n",
    "\n",
    "This alternative is useful when we need to define models with **multiple inputs/multiple outputs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = tf.keras.Input(shape=(28*28,))\n",
    "# hid1 = tf.keras.layers.Dense(256, activation='sigmoid')(input)\n",
    "# hid2 = tf.keras.layers.Dense(128, activation='sigmoid')(hid1)\n",
    "# output = tf.keras.layers.Dense(num_classes,activation='softmax')(hid2)\n",
    "# model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">205,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │       \u001b[38;5;34m205,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m8,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,570</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m414,570\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,570</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m414,570\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "# It should ouput the ouput shape and number of parameters for each layer.\n",
    "# Notice that the None in the output shape tuples — like (None, 256) —\n",
    "# means that the batch size is not fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **First layer**:\n",
    "    - Input size = 784+1(+1 for bias)\n",
    "    - Output size = 256.\n",
    "    - Parameters = 200960 = (784+1) * 256\n",
    "\n",
    "- **Second layer**:\n",
    "    - Input size = 256+1\n",
    "    - Output size = 128.\n",
    "    - Parameters = 32896 = (256+1) * 128\n",
    "\n",
    "- **First layer**:\n",
    "    - Input size = 128+1\n",
    "    - Output size = 10.\n",
    "    - Parameters = 1290 = (128+1) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Model class provides a method, `compile()` to compile the model. It transform the model into a computational graph (possibly static), to get best execution performance.\n",
    "\n",
    "This prepares the model to be trained with `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # optimizer = How the model updates weights (Stochastic Gradient Descent here)\n",
    "    optimizer='SGD',\n",
    "    # loss = How the model calculates the error\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # metrics = How the model evaluates its performance\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4726 - loss: 1.9181 - val_accuracy: 0.8590 - val_loss: 0.8613\n",
      "Epoch 2/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.7851 - val_accuracy: 0.9058 - val_loss: 0.4676\n",
      "Epoch 3/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.4985 - val_accuracy: 0.9188 - val_loss: 0.3474\n",
      "Epoch 4/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.3958 - val_accuracy: 0.9267 - val_loss: 0.2972\n",
      "Epoch 5/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3429 - val_accuracy: 0.9318 - val_loss: 0.2629\n",
      "Epoch 6/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.3096 - val_accuracy: 0.9383 - val_loss: 0.2412\n",
      "Epoch 7/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2827 - val_accuracy: 0.9392 - val_loss: 0.2253\n",
      "Epoch 8/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2645 - val_accuracy: 0.9427 - val_loss: 0.2132\n",
      "Epoch 9/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2476 - val_accuracy: 0.9453 - val_loss: 0.2038\n",
      "Epoch 10/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.2346 - val_accuracy: 0.9472 - val_loss: 0.1940\n",
      "Epoch 11/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.2219 - val_accuracy: 0.9507 - val_loss: 0.1841\n",
      "Epoch 12/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.2116 - val_accuracy: 0.9515 - val_loss: 0.1778\n",
      "Epoch 13/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2018 - val_accuracy: 0.9540 - val_loss: 0.1731\n",
      "Epoch 14/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1940 - val_accuracy: 0.9542 - val_loss: 0.1670\n",
      "Epoch 15/15\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1873 - val_accuracy: 0.9552 - val_loss: 0.1615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x314821610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we predict with our MLP in the test data.\n",
    "\n",
    "Each prediction is a list with the probabilities for each digit (0 to 9). We then need to choose the maximum number to be the winner, we use `np.argmax()` that returns the index of the maximum element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step\n",
      "predictions.shape: (10000, 10) \n",
      "\n",
      "Example of softmax prediction: \n",
      " [7.2415904e-05 1.4409322e-05 4.0726861e-04 2.2217340e-03 6.7918472e-06\n",
      " 4.3300151e-05 1.6030624e-07 9.9655676e-01 1.0417885e-05 6.6663086e-04]\n",
      "\n",
      "category_predictions.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(f\"predictions.shape: {predictions.shape} \\n\")\n",
    "\n",
    "print(f\"Example of softmax prediction: \\n {predictions[0]}\")\n",
    "category_predictions = np.argmax(predictions, axis=1)\n",
    "print(f\"\\ncategory_predictions.shape: {category_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of a prediction and check the actual element to see if the MLP is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x321c434d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(category_predictions[0])\n",
    "# And let's check the image so we can confirm its actually a 7\n",
    "from matplotlib import pyplot as plt\n",
    "image = X_test[0].reshape(28,28)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like its working correctly! Let's now compute the test accurracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, category_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the training data into train and validation sets (use for instance 80% and 20%)\n",
    "* Operate a model selection for the following hyper-parameters\n",
    "    1. **Number of layers** (for instance try 1 or 2 hidden layers)\n",
    "    2. **Number of hidden units** fixed the numer of layers (128 or 256)\n",
    "    3. **Batch size** (try 32 or 128). What main differences do you observe?\n",
    "* Evaluate if the number of epochs is large enough\n",
    "\n",
    "#### What to do:\n",
    "1. Split original training data into train and validation sets again.\n",
    "2. Fix a set of possible configurations for all hyper-parameters.\n",
    "3. Loop over any possible configuration\n",
    "    * For any config, train a model on training data.\n",
    "    * Evaluate the performance on validation data\n",
    "    * Pick the configuration having the highest accuracy on validation data\n",
    "4. Merge again train and validation data to get a unique training set\n",
    "5. Train the final model with the chosen configuration and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape:(48000, 784),  \n",
      "val_data.shape:(12000, 784)\n",
      "train_labels.shape:(48000,), \n",
      "val_labels.shape:(12000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Split the Training dataset into Training and Validation again\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X_train, y_train,\n",
    "                                                            test_size=0.2)\n",
    "\n",
    "print(f\"train_data.shape:{train_data.shape},  \\nval_data.shape:{val_data.shape}\")\n",
    "print(f\"train_labels.shape:{train_labels.shape}, \\nval_labels.shape:{val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Fix all the possible configurations for all hyper-parameters\n",
    "from itertools import product\n",
    "\n",
    "# Define the possible values for each hyperparameter\n",
    "num_layers = [1, 2]\n",
    "hidden_units = [128, 256]\n",
    "batch_size = [32, 128]\n",
    "\n",
    "# Create all combinations of configurations\n",
    "configs = list(product(num_layers, hidden_units, batch_size))\n",
    "\n",
    "# Format them as dictionaries\n",
    "config_dicts = [\n",
    "    {\"num_layers\": nl, \"hidden_units\": hu, \"batch_size\": bs}\n",
    "    for nl, hu, bs in configs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step\n",
      "Config: {'num_layers': 1, 'hidden_units': 128, 'batch_size': 32}\n",
      "Accuracy: 0.9405833333333333\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step\n",
      "Config: {'num_layers': 1, 'hidden_units': 128, 'batch_size': 128}\n",
      "Accuracy: 0.93325\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "Config: {'num_layers': 1, 'hidden_units': 256, 'batch_size': 32}\n",
      "Accuracy: 0.9525\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step\n",
      "Config: {'num_layers': 1, 'hidden_units': 256, 'batch_size': 128}\n",
      "Accuracy: 0.9426666666666667\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step\n",
      "Config: {'num_layers': 2, 'hidden_units': 128, 'batch_size': 32}\n",
      "Accuracy: 0.9390833333333334\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step\n",
      "Config: {'num_layers': 2, 'hidden_units': 128, 'batch_size': 128}\n",
      "Accuracy: 0.9164166666666667\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n",
      "Config: {'num_layers': 2, 'hidden_units': 256, 'batch_size': 32}\n",
      "Accuracy: 0.9493333333333334\n",
      "\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n",
      "Config: {'num_layers': 2, 'hidden_units': 256, 'batch_size': 128}\n",
      "Accuracy: 0.9248333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Let's now iterate over all the possible configs and train a model for each one\n",
    "best_config = (None, 0) # (best_config, accurracy)\n",
    "\n",
    "for config in config_dicts:\n",
    "    # Create the model for each configuration\n",
    "    model = Sequential()\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        model.add(Dense(config[\"hidden_units\"], activation='sigmoid'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='SGD',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size = config[\"batch_size\"],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(val_data)\n",
    "    category_predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(val_labels, category_predictions)\n",
    "    \n",
    "    print(f\"Config: {config}\\nAccuracy: {accuracy}\\n\")\n",
    "\n",
    "    # Update the best configuration\n",
    "    if accuracy > best_config[1]:\n",
    "        best_config = (config, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Merge the training and validation datasets to get a unique training dataset.\n",
    "X_train = np.concatenate([train_data, val_data])\n",
    "y_train = np.concatenate([train_labels, val_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7682 - loss: 0.8377\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.9095 - loss: 0.3321\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.9229 - loss: 0.2757\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.9325 - loss: 0.2432\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802us/step - accuracy: 0.9380 - loss: 0.2202\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806us/step - accuracy: 0.9427 - loss: 0.2067\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.9448 - loss: 0.1954\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.9476 - loss: 0.1831\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.9499 - loss: 0.1756\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.9524 - loss: 0.1674\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.9535 - loss: 0.1641\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.9541 - loss: 0.1608\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.9562 - loss: 0.1533\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.9582 - loss: 0.1492\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.9606 - loss: 0.1431\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.9592 - loss: 0.1399\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.9615 - loss: 0.1351\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.9611 - loss: 0.1352\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.9631 - loss: 0.1302\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.9624 - loss: 0.1316\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step\n",
      "Accuracy of the best configuration: 0.9594\n",
      "Same as above but only trained on the sub-trianing set: 0.9525\n"
     ]
    }
   ],
   "source": [
    "# 5) Train the model with the best configuration using the unique training dataset.\n",
    "model = Sequential()\n",
    "for i in range(best_config[0][\"num_layers\"]):\n",
    "    model.add(Dense(best_config[0][\"hidden_units\"], activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20, # After 20 epochs, the accuracy starts decreasing\n",
    "    batch_size = best_config[0][\"batch_size\"]\n",
    ")\n",
    "\n",
    "# Evaluate the model with the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "category_predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, category_predictions)\n",
    "print(f\"Accuracy of the best configuration: {accuracy}\")\n",
    "print(f\"Same as above but only trained on the sub-trianing set: {best_config[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
